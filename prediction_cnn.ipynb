{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           照片 Picture 品牌 Brand 衣服長度 Clothes Length  價格 Price  \\\n",
      "0     image_00000.jpg      H&M             短 short       499   \n",
      "1     image_00001.jpg      H&M              長 long       999   \n",
      "2     image_00002.jpg      H&M              長 long       699   \n",
      "3     image_00003.jpg      H&M              長 long       999   \n",
      "4     image_00004.jpg      H&M              長 long       699   \n",
      "...               ...      ...                 ...       ...   \n",
      "2228  image_02228.jpg    Lativ             短 short       199   \n",
      "2229  image_02229.jpg    Lativ             短 short       299   \n",
      "2230  image_02230.jpg    Lativ             短 short       249   \n",
      "2231  image_02231.jpg    Lativ             短 short       499   \n",
      "2232  image_02232.jpg    Lativ             短 short       590   \n",
      "\n",
      "      西裝褲、裙 dress pants、skirt  背心 Vest  牛仔褲/裙 jeans / demi skirt  \\\n",
      "0                         0.0      0.0                       0.0   \n",
      "1                         0.0      0.0                       0.0   \n",
      "2                         0.0      0.0                       0.0   \n",
      "3                         1.0      0.0                       0.0   \n",
      "4                         0.0      0.0                       0.0   \n",
      "...                       ...      ...                       ...   \n",
      "2228                      0.0      1.0                       0.0   \n",
      "2229                      0.0      1.0                       0.0   \n",
      "2230                      0.0      1.0                       0.0   \n",
      "2231                      0.0      1.0                       0.0   \n",
      "2232                      0.0      1.0                       0.0   \n",
      "\n",
      "      工裝褲/裙 cargo pants/skirt  上半身 Top  吊帶褲/裙 overalls/jumper skirt  ...  \\\n",
      "0                         0.0      1.0                          0.0  ...   \n",
      "1                         0.0      1.0                          0.0  ...   \n",
      "2                         0.0      0.0                          0.0  ...   \n",
      "3                         0.0      0.0                          0.0  ...   \n",
      "4                         1.0      0.0                          0.0  ...   \n",
      "...                       ...      ...                          ...  ...   \n",
      "2228                      0.0      1.0                          0.0  ...   \n",
      "2229                      0.0      1.0                          0.0  ...   \n",
      "2230                      0.0      1.0                          0.0  ...   \n",
      "2231                      0.0      1.0                          0.0  ...   \n",
      "2232                      0.0      1.0                          0.0  ...   \n",
      "\n",
      "      運動褲/裙 sweat pants / sports skirt  下半身 Bottom  外套 Jacket  毛衣、針織衣 Sweater  \\\n",
      "0                                  0.0         0.0        0.0             0.0   \n",
      "1                                  0.0         0.0        0.0             0.0   \n",
      "2                                  0.0         0.0        0.0             0.0   \n",
      "3                                  0.0         1.0        0.0             0.0   \n",
      "4                                  0.0         1.0        0.0             0.0   \n",
      "...                                ...         ...        ...             ...   \n",
      "2228                               0.0         0.0        0.0             0.0   \n",
      "2229                               0.0         0.0        0.0             0.0   \n",
      "2230                               0.0         0.0        0.0             0.0   \n",
      "2231                               0.0         0.0        0.0             1.0   \n",
      "2232                               0.0         0.0        0.0             1.0   \n",
      "\n",
      "      百褶裙 pleated skirt  連帽衣 Hoodie  牛仔材質 Denim  T-Shirt  褲子 pants  \\\n",
      "0                   0.0         0.0         0.0      1.0       0.0   \n",
      "1                   0.0         0.0         0.0      0.0       0.0   \n",
      "2                   0.0         0.0         0.0      0.0       0.0   \n",
      "3                   0.0         0.0         0.0      0.0       1.0   \n",
      "4                   0.0         0.0         0.0      0.0       0.0   \n",
      "...                 ...         ...         ...      ...       ...   \n",
      "2228                0.0         0.0         0.0      0.0       0.0   \n",
      "2229                0.0         0.0         0.0      0.0       0.0   \n",
      "2230                0.0         0.0         0.0      0.0       0.0   \n",
      "2231                0.0         0.0         0.0      0.0       0.0   \n",
      "2232                0.0         0.0         0.0      0.0       0.0   \n",
      "\n",
      "      運動材質 Sport Tops  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "...               ...  \n",
      "2228              0.0  \n",
      "2229              0.0  \n",
      "2230              0.0  \n",
      "2231              0.0  \n",
      "2232              0.0  \n",
      "\n",
      "[2233 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"./processed.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['西裝褲、裙 dress pants、skirt', '背心 Vest', '牛仔褲/裙 jeans / demi skirt',\n",
      "       '工裝褲/裙 cargo pants/skirt', '上半身 Top', '吊帶褲/裙 overalls/jumper skirt',\n",
      "       '羽絨衣 Down coat / jacket', '網紗 Mesh', '裙子 skirt', '毛衣、針/織衣 Sweater',\n",
      "       '西裝 Suit', '緊身褲 leggings', '休閒褲/裙 casual pants/skirt', '洋裝 Dress',\n",
      "       'Shirt', '運動褲/裙 sweat pants / sports skirt', '下半身 Bottom', '外套 Jacket',\n",
      "       '毛衣、針織衣 Sweater', '百褶裙 pleated skirt', '連帽衣 Hoodie', '牛仔材質 Denim',\n",
      "       'T-Shirt', '褲子 pants', '運動材質 Sport Tops', 'filepath',\n",
      "       '品牌 Brand_50 percent', '品牌 Brand_AIR SPACE', '品牌 Brand_Adidas',\n",
      "       '品牌 Brand_GAP', '品牌 Brand_H&M', '品牌 Brand_Lativ', '品牌 Brand_Net',\n",
      "       '品牌 Brand_New Balance', '品牌 Brand_Nike', '品牌 Brand_PAZZO',\n",
      "       '品牌 Brand_Puma', '品牌 Brand_Under Armour', '品牌 Brand_Uniqlo',\n",
      "       '衣服長度 Clothes Length_短 short', '衣服長度 Clothes Length_長 long'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "target = \"價格 Price\"\n",
    "# print(df)\n",
    "y = df[target]\n",
    "image_dir = \"./clothes_data\"\n",
    "df[\"filepath\"] = df[\"照片 Picture\"].apply(lambda x: os.path.join(image_dir, f\"{x}\"))\n",
    "X = df\n",
    "X = X.drop(columns=[target, \"照片 Picture\"])  # Features\n",
    "\n",
    "# remove invalid datas\n",
    "\n",
    "X = pd.get_dummies(X, columns=[\"品牌 Brand\"])\n",
    "X = pd.get_dummies(X, columns=[\"衣服長度 Clothes Length\"])\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "img_height, img_width = 180, 180\n",
    "image_shape = (img_height, img_width, 3)\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(filepath):\n",
    "    img = load_img(filepath, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize the image\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "X_train_images = np.array([load_and_preprocess_image(fp) for fp in X_train[\"filepath\"]])\n",
    "X_test_images = np.array([load_and_preprocess_image(fp) for fp in X_test[\"filepath\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_features = scaler.fit_transform(X_train.drop(\"filepath\", axis=1))\n",
    "X_test_features = scaler.transform(X_test.drop(\"filepath\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doo12\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['Image_Input', 'Feature_Input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - loss: 3111998.0000 - mae: 1287.9142 - val_loss: 1688526.1250 - val_mae: 1045.7212\n",
      "Epoch 2/50\n",
      "\u001b[1m55/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2574822.2500 - mae: 1129.7429"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 38\u001b[0m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Concatenate,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "image_input = Input(shape=image_shape, name=\"Image_Input\")\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "feature_input = Input(shape=(X_train_features.shape[1],), name=\"Feature_Input\")\n",
    "y = Dense(64, activation=\"relu\")(feature_input)\n",
    "y = Dropout(0.3)(y)\n",
    "\n",
    "combined = Concatenate()([x, y])\n",
    "z = Dense(64, activation=\"relu\")(combined)\n",
    "z = Dropout(0.5)(z)\n",
    "output = Dense(1)(z)\n",
    "\n",
    "model = Model(inputs=[image_input, feature_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_images, X_train_features],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_test_images, X_test_features], y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doo12\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5067412.0000 - mae: 1699.7081 - val_loss: 3868976.7500 - val_mae: 1513.7045\n",
      "Epoch 2/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 5086533.5000 - mae: 1693.3818 - val_loss: 3777908.2500 - val_mae: 1490.2513\n",
      "Epoch 3/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 5142854.0000 - mae: 1677.2030 - val_loss: 3516654.0000 - val_mae: 1425.7789\n",
      "Epoch 4/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 4639440.5000 - mae: 1588.9138 - val_loss: 3001814.7500 - val_mae: 1294.5140\n",
      "Epoch 5/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3970331.5000 - mae: 1456.0177 - val_loss: 2250320.0000 - val_mae: 1079.7538\n",
      "Epoch 6/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 3188367.5000 - mae: 1221.3269 - val_loss: 1492630.2500 - val_mae: 819.9245\n",
      "Epoch 7/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 2046791.8750 - mae: 915.9701 - val_loss: 963343.7500 - val_mae: 617.3737\n",
      "Epoch 8/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1234936.6250 - mae: 678.1558 - val_loss: 730917.8125 - val_mae: 554.1135\n",
      "Epoch 9/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 936388.4375 - mae: 616.6092 - val_loss: 655926.4375 - val_mae: 545.1100\n",
      "Epoch 10/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 762456.5625 - mae: 577.7120 - val_loss: 619977.0625 - val_mae: 537.8750\n",
      "Epoch 11/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 785453.0000 - mae: 567.4552 - val_loss: 590175.8125 - val_mae: 526.6372\n",
      "Epoch 12/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 691791.6250 - mae: 545.7961 - val_loss: 567759.8750 - val_mae: 512.6393\n",
      "Epoch 13/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 730643.9375 - mae: 560.5965 - val_loss: 553357.1875 - val_mae: 503.1761\n",
      "Epoch 14/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 645786.6875 - mae: 524.9625 - val_loss: 534440.3125 - val_mae: 488.6366\n",
      "Epoch 15/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 590706.3750 - mae: 508.0506 - val_loss: 524393.9375 - val_mae: 480.2032\n",
      "Epoch 16/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 565625.9375 - mae: 489.6451 - val_loss: 517281.3750 - val_mae: 474.3472\n",
      "Epoch 17/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 575483.3750 - mae: 493.4579 - val_loss: 510163.4688 - val_mae: 469.9443\n",
      "Epoch 18/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 593426.1250 - mae: 487.5588 - val_loss: 503178.6562 - val_mae: 464.7663\n",
      "Epoch 19/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 577894.6875 - mae: 485.3918 - val_loss: 493888.2812 - val_mae: 458.1555\n",
      "Epoch 20/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508736.7812 - mae: 452.3942 - val_loss: 488881.6562 - val_mae: 454.6512\n",
      "Epoch 21/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 486745.5312 - mae: 453.5534 - val_loss: 487827.0000 - val_mae: 454.4904\n",
      "Epoch 22/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 555333.1875 - mae: 482.5793 - val_loss: 481129.6562 - val_mae: 449.6991\n",
      "Epoch 23/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 539552.0625 - mae: 471.2425 - val_loss: 478175.5938 - val_mae: 447.6053\n",
      "Epoch 24/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 464900.7812 - mae: 438.3017 - val_loss: 474814.8125 - val_mae: 447.0064\n",
      "Epoch 25/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 477536.8125 - mae: 449.1015 - val_loss: 472491.7500 - val_mae: 445.7680\n",
      "Epoch 26/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 510167.3438 - mae: 449.6237 - val_loss: 470358.0625 - val_mae: 444.9218\n",
      "Epoch 27/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 553459.1250 - mae: 468.4332 - val_loss: 466140.5000 - val_mae: 442.3072\n",
      "Epoch 28/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 507375.8125 - mae: 452.7365 - val_loss: 464849.5000 - val_mae: 440.2300\n",
      "Epoch 29/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 514248.8438 - mae: 458.9355 - val_loss: 461471.7812 - val_mae: 439.1813\n",
      "Epoch 30/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 542142.8750 - mae: 459.7239 - val_loss: 461256.8125 - val_mae: 439.5565\n",
      "Epoch 31/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 553014.1875 - mae: 476.3992 - val_loss: 461204.1250 - val_mae: 439.7846\n",
      "Epoch 32/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 484204.6250 - mae: 445.4356 - val_loss: 460294.6562 - val_mae: 440.1958\n",
      "Epoch 33/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 486916.2500 - mae: 440.6363 - val_loss: 456825.1562 - val_mae: 436.7240\n",
      "Epoch 34/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 533172.1250 - mae: 454.0451 - val_loss: 454168.0625 - val_mae: 433.9478\n",
      "Epoch 35/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 479211.2500 - mae: 443.6050 - val_loss: 455141.8125 - val_mae: 435.6758\n",
      "Epoch 36/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 482639.7812 - mae: 437.1444 - val_loss: 453777.0625 - val_mae: 434.9498\n",
      "Epoch 37/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 472804.4375 - mae: 434.6605 - val_loss: 452732.9062 - val_mae: 434.5129\n",
      "Epoch 38/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 482599.2812 - mae: 446.4518 - val_loss: 451753.5000 - val_mae: 434.8156\n",
      "Epoch 39/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 462076.9688 - mae: 441.1054 - val_loss: 449787.5625 - val_mae: 433.0396\n",
      "Epoch 40/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 486650.5312 - mae: 447.2624 - val_loss: 446162.7500 - val_mae: 430.1317\n",
      "Epoch 41/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 487118.7500 - mae: 445.8962 - val_loss: 447433.4375 - val_mae: 431.8127\n",
      "Epoch 42/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 447044.1562 - mae: 422.6369 - val_loss: 444933.3750 - val_mae: 428.4874\n",
      "Epoch 43/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 509623.5000 - mae: 442.2886 - val_loss: 447461.0000 - val_mae: 430.9109\n",
      "Epoch 44/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 490605.5312 - mae: 454.6065 - val_loss: 443211.5000 - val_mae: 428.2317\n",
      "Epoch 45/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 462386.3438 - mae: 423.3380 - val_loss: 445184.2500 - val_mae: 430.9079\n",
      "Epoch 46/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 460323.9375 - mae: 422.3340 - val_loss: 443505.1250 - val_mae: 429.2258\n",
      "Epoch 47/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 406288.0312 - mae: 406.9913 - val_loss: 441445.5000 - val_mae: 427.9310\n",
      "Epoch 48/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 476897.5625 - mae: 442.3676 - val_loss: 442480.1562 - val_mae: 429.0202\n",
      "Epoch 49/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 493438.1562 - mae: 443.9255 - val_loss: 443550.4375 - val_mae: 429.2480\n",
      "Epoch 50/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 523734.5625 - mae: 460.1779 - val_loss: 439784.7188 - val_mae: 426.6177\n",
      "Epoch 51/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 465957.0938 - mae: 432.0988 - val_loss: 436709.2500 - val_mae: 423.1555\n",
      "Epoch 52/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 447308.6562 - mae: 426.9119 - val_loss: 437331.7812 - val_mae: 424.1637\n",
      "Epoch 53/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 478201.0938 - mae: 436.9047 - val_loss: 438511.9688 - val_mae: 425.4788\n",
      "Epoch 54/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 449073.6875 - mae: 433.8181 - val_loss: 438572.9062 - val_mae: 425.5692\n",
      "Epoch 55/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 432102.2812 - mae: 413.8372 - val_loss: 439065.8125 - val_mae: 425.5515\n",
      "Epoch 56/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 482587.4688 - mae: 436.0465 - val_loss: 434905.6562 - val_mae: 422.5942\n",
      "Epoch 57/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 475772.9062 - mae: 429.4783 - val_loss: 434438.9375 - val_mae: 421.9492\n",
      "Epoch 58/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 424659.4688 - mae: 420.2086 - val_loss: 435210.2500 - val_mae: 423.0945\n",
      "Epoch 59/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 452705.0625 - mae: 422.6947 - val_loss: 432648.3438 - val_mae: 421.1079\n",
      "Epoch 60/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 450654.0938 - mae: 429.6406 - val_loss: 432875.3438 - val_mae: 421.0444\n",
      "Epoch 61/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 441427.3125 - mae: 416.3432 - val_loss: 431501.9375 - val_mae: 418.8512\n",
      "Epoch 62/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 496295.5000 - mae: 441.2554 - val_loss: 431297.8125 - val_mae: 418.1554\n",
      "Epoch 63/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 413807.6250 - mae: 404.7730 - val_loss: 432068.1562 - val_mae: 418.5744\n",
      "Epoch 64/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 431641.3438 - mae: 419.3357 - val_loss: 432421.3125 - val_mae: 420.2988\n",
      "Epoch 65/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 439043.7812 - mae: 410.6013 - val_loss: 430557.1875 - val_mae: 419.0628\n",
      "Epoch 66/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 401675.1250 - mae: 408.1837 - val_loss: 429031.5312 - val_mae: 417.1850\n",
      "Epoch 67/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 433387.8125 - mae: 419.9695 - val_loss: 431913.0312 - val_mae: 419.2492\n",
      "Epoch 68/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 452444.0938 - mae: 421.0553 - val_loss: 429588.7188 - val_mae: 416.8071\n",
      "Epoch 69/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 456366.6562 - mae: 427.5870 - val_loss: 430273.3125 - val_mae: 417.7098\n",
      "Epoch 70/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 440992.8125 - mae: 414.6974 - val_loss: 429519.2812 - val_mae: 417.0813\n",
      "Epoch 71/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 457814.1562 - mae: 423.1811 - val_loss: 428650.5625 - val_mae: 415.5680\n",
      "Epoch 72/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 389031.5312 - mae: 399.2697 - val_loss: 425583.7500 - val_mae: 412.9647\n",
      "Epoch 73/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 395846.8125 - mae: 402.4503 - val_loss: 430161.0625 - val_mae: 417.2608\n",
      "Epoch 74/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 422185.6875 - mae: 414.9948 - val_loss: 428106.1875 - val_mae: 416.5857\n",
      "Epoch 75/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 467545.5625 - mae: 415.7739 - val_loss: 426511.3125 - val_mae: 413.8528\n",
      "Epoch 76/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 388599.3438 - mae: 406.7916 - val_loss: 424078.5938 - val_mae: 411.8249\n",
      "Epoch 77/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 430428.9062 - mae: 404.0272 - val_loss: 425255.1875 - val_mae: 413.7412\n",
      "Epoch 78/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 447891.9062 - mae: 422.2235 - val_loss: 424754.4688 - val_mae: 412.2105\n",
      "Epoch 79/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 420226.8125 - mae: 406.4520 - val_loss: 424436.2500 - val_mae: 412.2628\n",
      "Epoch 80/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 459724.0312 - mae: 424.2023 - val_loss: 424384.4688 - val_mae: 411.5504\n",
      "Epoch 81/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 430965.1562 - mae: 415.8530 - val_loss: 423873.8750 - val_mae: 411.4780\n",
      "Epoch 82/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 455744.7500 - mae: 415.3741 - val_loss: 422466.1875 - val_mae: 410.0745\n",
      "Epoch 83/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 441285.2812 - mae: 415.1563 - val_loss: 423928.6250 - val_mae: 411.6916\n",
      "Epoch 84/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 443846.4688 - mae: 425.4684 - val_loss: 425557.9062 - val_mae: 412.6588\n",
      "Epoch 85/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 393438.5625 - mae: 393.7546 - val_loss: 423214.2188 - val_mae: 410.3584\n",
      "Epoch 86/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 459544.7188 - mae: 426.3096 - val_loss: 424305.2812 - val_mae: 411.3051\n",
      "Epoch 87/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 486375.4062 - mae: 434.1066 - val_loss: 422263.1875 - val_mae: 409.5961\n",
      "Epoch 88/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 403769.3750 - mae: 400.9655 - val_loss: 422717.3750 - val_mae: 410.3768\n",
      "Epoch 89/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 400946.1562 - mae: 405.9389 - val_loss: 422559.5625 - val_mae: 409.8735\n",
      "Epoch 90/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 425297.2812 - mae: 406.7906 - val_loss: 422616.5312 - val_mae: 410.4214\n",
      "Epoch 91/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 416726.4375 - mae: 404.5506 - val_loss: 424120.1250 - val_mae: 410.6651\n",
      "Epoch 92/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 422204.1875 - mae: 401.2406 - val_loss: 423542.0938 - val_mae: 410.1218\n",
      "Epoch 93/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 403777.6250 - mae: 396.4525 - val_loss: 422897.2500 - val_mae: 410.6077\n",
      "Epoch 94/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 422428.4062 - mae: 407.2209 - val_loss: 421087.9688 - val_mae: 408.5605\n",
      "Epoch 95/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 363160.7812 - mae: 377.9843 - val_loss: 418263.5312 - val_mae: 407.1465\n",
      "Epoch 96/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 436445.1250 - mae: 408.3546 - val_loss: 420846.7188 - val_mae: 407.8891\n",
      "Epoch 97/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 386076.6250 - mae: 392.1055 - val_loss: 419203.8750 - val_mae: 406.2508\n",
      "Epoch 98/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 402173.4688 - mae: 396.0728 - val_loss: 419531.2188 - val_mae: 407.2787\n",
      "Epoch 99/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 404538.0312 - mae: 398.9876 - val_loss: 418628.9688 - val_mae: 405.8159\n",
      "Epoch 100/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 399252.0312 - mae: 390.8300 - val_loss: 417798.9375 - val_mae: 405.4198\n",
      "Epoch 101/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 365756.2188 - mae: 385.8296 - val_loss: 418063.5312 - val_mae: 405.5913\n",
      "Epoch 102/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 445880.6250 - mae: 414.3395 - val_loss: 420349.8750 - val_mae: 406.5721\n",
      "Epoch 103/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 381277.6875 - mae: 384.1640 - val_loss: 417640.6562 - val_mae: 404.8978\n",
      "Epoch 104/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 438979.2812 - mae: 408.1658 - val_loss: 417006.5312 - val_mae: 403.8706\n",
      "Epoch 105/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 418140.0312 - mae: 400.0464 - val_loss: 416388.6875 - val_mae: 404.5471\n",
      "Epoch 106/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 354200.9375 - mae: 375.7844 - val_loss: 417310.5312 - val_mae: 403.7959\n",
      "Epoch 107/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 399833.3438 - mae: 394.0351 - val_loss: 418743.4375 - val_mae: 405.5951\n",
      "Epoch 108/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 447840.8125 - mae: 411.4370 - val_loss: 416380.6562 - val_mae: 403.4693\n",
      "Epoch 109/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 405434.9375 - mae: 393.5230 - val_loss: 416140.5000 - val_mae: 403.4547\n",
      "Epoch 110/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 379392.6875 - mae: 385.2229 - val_loss: 418155.1562 - val_mae: 405.0819\n",
      "Epoch 111/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 401134.9688 - mae: 397.0188 - val_loss: 414885.3438 - val_mae: 402.0327\n",
      "Epoch 112/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 454013.3125 - mae: 406.7141 - val_loss: 415828.2812 - val_mae: 402.7854\n",
      "Epoch 113/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 426857.8750 - mae: 409.6867 - val_loss: 415499.4688 - val_mae: 403.1472\n",
      "Epoch 114/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 378375.0312 - mae: 390.4567 - val_loss: 413749.0000 - val_mae: 401.1294\n",
      "Epoch 115/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 410034.5625 - mae: 392.9839 - val_loss: 414396.2188 - val_mae: 401.6535\n",
      "Epoch 116/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 402750.7188 - mae: 402.5179 - val_loss: 411091.0000 - val_mae: 399.3205\n",
      "Epoch 117/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 431993.4375 - mae: 407.5476 - val_loss: 413308.6562 - val_mae: 400.7759\n",
      "Epoch 118/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 408281.9688 - mae: 395.2846 - val_loss: 413191.9375 - val_mae: 401.1232\n",
      "Epoch 119/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 398044.5000 - mae: 391.8005 - val_loss: 412034.4375 - val_mae: 398.9067\n",
      "Epoch 120/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 397076.5312 - mae: 392.6503 - val_loss: 414820.1250 - val_mae: 401.5604\n",
      "Epoch 121/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 366842.4062 - mae: 375.4017 - val_loss: 413301.0625 - val_mae: 400.7236\n",
      "Epoch 122/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 359226.5625 - mae: 380.8644 - val_loss: 413756.5625 - val_mae: 400.7658\n",
      "Epoch 123/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 402510.2188 - mae: 394.6569 - val_loss: 413117.5938 - val_mae: 400.4200\n",
      "Epoch 124/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 381795.3125 - mae: 383.5426 - val_loss: 413545.6562 - val_mae: 400.7363\n",
      "Epoch 125/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 426529.4375 - mae: 405.3492 - val_loss: 411047.4062 - val_mae: 398.1093\n",
      "Epoch 126/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 415645.8438 - mae: 393.9663 - val_loss: 411686.8750 - val_mae: 398.6980\n",
      "Epoch 127/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 423322.7500 - mae: 403.9396 - val_loss: 407763.8750 - val_mae: 395.8932\n",
      "Epoch 128/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 416212.7812 - mae: 400.8889 - val_loss: 410691.0938 - val_mae: 398.4791\n",
      "Epoch 129/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 425799.1875 - mae: 400.9225 - val_loss: 407335.6562 - val_mae: 395.0033\n",
      "Epoch 130/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 431523.7500 - mae: 389.2829 - val_loss: 408727.4062 - val_mae: 397.6812\n",
      "Epoch 131/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 353922.1875 - mae: 371.1777 - val_loss: 413897.5000 - val_mae: 400.8976\n",
      "Epoch 132/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 428656.0000 - mae: 401.9465 - val_loss: 406559.0000 - val_mae: 395.3045\n",
      "Epoch 133/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 405192.3125 - mae: 389.6501 - val_loss: 411646.5312 - val_mae: 398.6176\n",
      "Epoch 134/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 434822.3438 - mae: 403.9322 - val_loss: 408553.0625 - val_mae: 395.7967\n",
      "Epoch 135/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 383622.2188 - mae: 391.0490 - val_loss: 412688.0312 - val_mae: 399.2345\n",
      "Epoch 136/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 380902.3125 - mae: 382.5855 - val_loss: 410047.2500 - val_mae: 396.5344\n",
      "Epoch 137/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 389559.1250 - mae: 384.6313 - val_loss: 410691.2500 - val_mae: 397.4570\n",
      "Epoch 138/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 360809.9062 - mae: 377.1648 - val_loss: 409022.5000 - val_mae: 396.0397\n",
      "Epoch 139/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 414187.9375 - mae: 389.9576 - val_loss: 406390.0938 - val_mae: 394.7832\n",
      "Epoch 140/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 387143.3438 - mae: 384.7131 - val_loss: 405917.2812 - val_mae: 393.4454\n",
      "Epoch 141/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 356098.1875 - mae: 364.2418 - val_loss: 409677.6250 - val_mae: 396.5621\n",
      "Epoch 142/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 359719.0312 - mae: 366.3266 - val_loss: 408610.9375 - val_mae: 394.9147\n",
      "Epoch 143/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 415443.0000 - mae: 389.0093 - val_loss: 406548.4375 - val_mae: 393.3884\n",
      "Epoch 144/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 375172.4375 - mae: 375.5147 - val_loss: 406089.4375 - val_mae: 393.3944\n",
      "Epoch 145/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 353347.1562 - mae: 370.6937 - val_loss: 406812.7500 - val_mae: 393.4834\n",
      "Epoch 146/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 369067.6875 - mae: 370.7495 - val_loss: 405147.3438 - val_mae: 392.1652\n",
      "Epoch 147/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 364506.0938 - mae: 356.7756 - val_loss: 404617.5938 - val_mae: 393.1686\n",
      "Epoch 148/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 396796.3438 - mae: 375.6255 - val_loss: 404732.5312 - val_mae: 392.5437\n",
      "Epoch 149/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 411858.8750 - mae: 391.6493 - val_loss: 405124.5938 - val_mae: 393.7776\n",
      "Epoch 150/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 390011.4688 - mae: 382.2171 - val_loss: 406432.4375 - val_mae: 393.1260\n",
      "Epoch 151/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 402937.7500 - mae: 381.9659 - val_loss: 409331.6562 - val_mae: 395.0091\n",
      "Epoch 152/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 393998.4688 - mae: 385.8573 - val_loss: 405914.8438 - val_mae: 393.7882\n",
      "Epoch 153/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 383159.3125 - mae: 378.9992 - val_loss: 405905.2812 - val_mae: 393.0183\n",
      "Epoch 154/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 389411.9688 - mae: 381.5114 - val_loss: 405816.4062 - val_mae: 393.8050\n",
      "Epoch 155/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 332256.2812 - mae: 359.8919 - val_loss: 404006.3438 - val_mae: 392.1246\n",
      "Epoch 156/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 375438.6562 - mae: 372.7893 - val_loss: 404639.2500 - val_mae: 391.8384\n",
      "Epoch 157/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 419555.3750 - mae: 389.8516 - val_loss: 401767.5625 - val_mae: 390.4424\n",
      "Epoch 158/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 398963.3438 - mae: 380.6852 - val_loss: 402213.8125 - val_mae: 389.8612\n",
      "Epoch 159/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 361246.0312 - mae: 377.9539 - val_loss: 403128.6562 - val_mae: 390.7292\n",
      "Epoch 160/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 454809.5625 - mae: 404.3484 - val_loss: 401271.4375 - val_mae: 390.3018\n",
      "Epoch 161/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 422369.9375 - mae: 385.5869 - val_loss: 404249.1875 - val_mae: 391.9742\n",
      "Epoch 162/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 435124.3438 - mae: 405.3432 - val_loss: 400828.1250 - val_mae: 388.9931\n",
      "Epoch 163/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 338266.2500 - mae: 355.2758 - val_loss: 403304.4062 - val_mae: 389.9732\n",
      "Epoch 164/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 387083.2812 - mae: 381.4242 - val_loss: 402482.9375 - val_mae: 391.2353\n",
      "Epoch 165/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 361148.2500 - mae: 373.0984 - val_loss: 401555.2188 - val_mae: 390.2062\n",
      "Epoch 166/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 418800.7812 - mae: 392.1342 - val_loss: 403738.0938 - val_mae: 391.1746\n",
      "Epoch 167/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 416027.1875 - mae: 390.5455 - val_loss: 401830.6562 - val_mae: 389.7160\n",
      "Epoch 168/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 360034.3438 - mae: 376.4279 - val_loss: 404110.1250 - val_mae: 391.1067\n",
      "Epoch 169/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 360861.5625 - mae: 362.1933 - val_loss: 400231.4062 - val_mae: 389.4095\n",
      "Epoch 170/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 374096.3438 - mae: 380.0263 - val_loss: 400301.3438 - val_mae: 389.4665\n",
      "Epoch 171/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 344362.5938 - mae: 363.9245 - val_loss: 398266.4375 - val_mae: 388.1192\n",
      "Epoch 172/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 383295.0625 - mae: 383.2359 - val_loss: 398542.1875 - val_mae: 388.1259\n",
      "Epoch 173/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 392428.4062 - mae: 390.1252 - val_loss: 399540.3750 - val_mae: 388.8892\n",
      "Epoch 174/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 364281.8438 - mae: 372.0323 - val_loss: 400837.9375 - val_mae: 389.5611\n",
      "Epoch 175/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 383195.5938 - mae: 359.6016 - val_loss: 399270.8750 - val_mae: 388.6137\n",
      "Epoch 176/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 368407.0938 - mae: 366.6342 - val_loss: 401550.4375 - val_mae: 389.0927\n",
      "Epoch 177/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 349140.4062 - mae: 365.4421 - val_loss: 400140.6562 - val_mae: 389.4498\n",
      "Epoch 178/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 416214.6875 - mae: 395.3173 - val_loss: 400804.7188 - val_mae: 389.0358\n",
      "Epoch 179/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 384730.3438 - mae: 374.4688 - val_loss: 398159.4375 - val_mae: 388.2381\n",
      "Epoch 180/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 347419.7188 - mae: 359.4668 - val_loss: 403341.3438 - val_mae: 391.2301\n",
      "Epoch 181/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 371197.3125 - mae: 369.7659 - val_loss: 399454.7812 - val_mae: 388.5563\n",
      "Epoch 182/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 378733.2188 - mae: 376.3686 - val_loss: 397573.8438 - val_mae: 387.2170\n",
      "Epoch 183/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 408119.5938 - mae: 388.8488 - val_loss: 396570.9062 - val_mae: 386.7064\n",
      "Epoch 184/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 357148.7188 - mae: 365.6944 - val_loss: 396636.3438 - val_mae: 388.0611\n",
      "Epoch 185/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 388576.4062 - mae: 382.1680 - val_loss: 397661.3750 - val_mae: 387.6527\n",
      "Epoch 186/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 359480.6250 - mae: 378.1982 - val_loss: 400317.5000 - val_mae: 388.7796\n",
      "Epoch 187/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 369060.2188 - mae: 368.8299 - val_loss: 397848.2812 - val_mae: 387.7930\n",
      "Epoch 188/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 362102.0625 - mae: 367.8674 - val_loss: 402065.3750 - val_mae: 390.0245\n",
      "Epoch 189/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 393782.0000 - mae: 389.0364 - val_loss: 395896.8750 - val_mae: 387.0192\n",
      "Epoch 190/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 364496.1562 - mae: 368.4489 - val_loss: 395278.9688 - val_mae: 386.5076\n",
      "Epoch 191/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 393460.6875 - mae: 382.4883 - val_loss: 397937.6250 - val_mae: 388.1671\n",
      "Epoch 192/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 380323.9375 - mae: 380.8369 - val_loss: 396839.3438 - val_mae: 386.4454\n",
      "Epoch 193/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 361519.2812 - mae: 370.8691 - val_loss: 399575.7812 - val_mae: 388.5195\n",
      "Epoch 194/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 368756.2188 - mae: 354.2005 - val_loss: 397628.7812 - val_mae: 387.2805\n",
      "Epoch 195/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 336939.6562 - mae: 355.2801 - val_loss: 396582.4062 - val_mae: 387.1017\n",
      "Epoch 196/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 419612.0000 - mae: 373.4857 - val_loss: 395538.4688 - val_mae: 386.5909\n",
      "Epoch 197/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 408181.6250 - mae: 387.0598 - val_loss: 396337.4062 - val_mae: 386.6563\n",
      "Epoch 198/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 391835.1875 - mae: 375.9520 - val_loss: 392842.8438 - val_mae: 384.6909\n",
      "Epoch 199/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 374552.7812 - mae: 372.1005 - val_loss: 394220.9062 - val_mae: 384.7732\n",
      "Epoch 200/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 369815.4062 - mae: 372.5022 - val_loss: 391554.9375 - val_mae: 384.1784\n",
      "Epoch 201/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 342342.5312 - mae: 357.6257 - val_loss: 397289.0625 - val_mae: 387.1620\n",
      "Epoch 202/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 284541.1562 - mae: 342.2872 - val_loss: 393935.4062 - val_mae: 384.2390\n",
      "Epoch 203/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 431391.8438 - mae: 399.8496 - val_loss: 392775.4062 - val_mae: 384.9453\n",
      "Epoch 204/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 360769.5625 - mae: 370.6936 - val_loss: 393051.0625 - val_mae: 384.7223\n",
      "Epoch 205/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 417401.5000 - mae: 396.5024 - val_loss: 395091.0000 - val_mae: 386.0064\n",
      "Epoch 206/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 359919.3438 - mae: 361.2632 - val_loss: 394535.0938 - val_mae: 385.5564\n",
      "Epoch 207/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 379826.4375 - mae: 369.4805 - val_loss: 393443.8750 - val_mae: 384.8674\n",
      "Epoch 208/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 350140.5000 - mae: 371.8792 - val_loss: 392707.8750 - val_mae: 383.1402\n",
      "Epoch 209/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 339190.0625 - mae: 361.8891 - val_loss: 392864.4375 - val_mae: 384.0383\n",
      "Epoch 210/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 359438.8438 - mae: 371.6873 - val_loss: 394112.1562 - val_mae: 386.3310\n",
      "Epoch 211/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 389730.4688 - mae: 374.4424 - val_loss: 394427.0312 - val_mae: 385.5623\n",
      "Epoch 212/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 325648.1250 - mae: 359.6259 - val_loss: 395363.1562 - val_mae: 385.0933\n",
      "Epoch 213/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 343843.5625 - mae: 368.0823 - val_loss: 391184.5312 - val_mae: 383.0721\n",
      "Epoch 214/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 374004.0000 - mae: 369.6453 - val_loss: 391469.9375 - val_mae: 383.4144\n",
      "Epoch 215/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 350162.3438 - mae: 360.5140 - val_loss: 390199.9062 - val_mae: 382.7869\n",
      "Epoch 216/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 339431.4375 - mae: 358.1017 - val_loss: 390329.0938 - val_mae: 382.8795\n",
      "Epoch 217/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 337912.7500 - mae: 359.4112 - val_loss: 391694.9375 - val_mae: 383.9283\n",
      "Epoch 218/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 415659.2500 - mae: 387.0746 - val_loss: 390674.7188 - val_mae: 382.9092\n",
      "Epoch 219/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 350888.5625 - mae: 357.0262 - val_loss: 391857.0312 - val_mae: 383.6382\n",
      "Epoch 220/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 344215.9688 - mae: 357.5202 - val_loss: 389230.6875 - val_mae: 381.7743\n",
      "Epoch 221/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 382696.3125 - mae: 370.5355 - val_loss: 389407.6562 - val_mae: 382.1858\n",
      "Epoch 222/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 398584.2500 - mae: 382.0821 - val_loss: 391070.0938 - val_mae: 382.7435\n",
      "Epoch 223/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 378103.7188 - mae: 364.1246 - val_loss: 390146.9375 - val_mae: 382.7345\n",
      "Epoch 224/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 343754.3438 - mae: 344.9311 - val_loss: 389420.4688 - val_mae: 382.4213\n",
      "Epoch 225/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 378487.9062 - mae: 367.5814 - val_loss: 392000.2812 - val_mae: 383.7100\n",
      "Epoch 226/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 346414.8750 - mae: 361.7778 - val_loss: 388958.2812 - val_mae: 381.6676\n",
      "Epoch 227/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 362374.5000 - mae: 370.4308 - val_loss: 388213.3750 - val_mae: 381.4181\n",
      "Epoch 228/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 339359.1250 - mae: 352.2687 - val_loss: 393578.5938 - val_mae: 384.1589\n",
      "Epoch 229/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331516.4688 - mae: 351.9169 - val_loss: 389454.0625 - val_mae: 382.1503\n",
      "Epoch 230/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 366347.7812 - mae: 366.2595 - val_loss: 388772.1875 - val_mae: 380.9630\n",
      "Epoch 231/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 410168.7812 - mae: 390.4185 - val_loss: 387523.8750 - val_mae: 381.4010\n",
      "Epoch 232/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 358036.9062 - mae: 360.7414 - val_loss: 385453.0938 - val_mae: 379.5945\n",
      "Epoch 233/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 322497.0000 - mae: 353.7029 - val_loss: 392078.7188 - val_mae: 384.0598\n",
      "Epoch 234/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 326587.0625 - mae: 360.2828 - val_loss: 390261.1250 - val_mae: 382.2630\n",
      "Epoch 235/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 315072.7188 - mae: 338.2408 - val_loss: 389205.9062 - val_mae: 382.3971\n",
      "Epoch 236/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 405136.6250 - mae: 369.7090 - val_loss: 388421.9375 - val_mae: 381.5154\n",
      "Epoch 237/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 388075.1250 - mae: 382.3060 - val_loss: 391086.8750 - val_mae: 382.3944\n",
      "Epoch 238/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 338747.5000 - mae: 355.0452 - val_loss: 388066.3125 - val_mae: 380.8589\n",
      "Epoch 239/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 358789.4375 - mae: 370.2002 - val_loss: 388879.0312 - val_mae: 381.8086\n",
      "Epoch 240/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 377110.7188 - mae: 375.7778 - val_loss: 386320.5938 - val_mae: 379.5305\n",
      "Epoch 241/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 380950.4688 - mae: 369.7170 - val_loss: 385620.2812 - val_mae: 378.8174\n",
      "Epoch 242/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 346810.2500 - mae: 355.8957 - val_loss: 389280.0938 - val_mae: 381.1387\n",
      "Epoch 243/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 313319.7188 - mae: 347.3085 - val_loss: 387072.9688 - val_mae: 380.3598\n",
      "Epoch 244/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 424965.1250 - mae: 384.6352 - val_loss: 387295.1562 - val_mae: 380.4105\n",
      "Epoch 245/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 382183.1250 - mae: 368.6152 - val_loss: 388764.0938 - val_mae: 381.5732\n",
      "Epoch 246/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 342891.7188 - mae: 360.7957 - val_loss: 387429.6562 - val_mae: 380.2972\n",
      "Epoch 247/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 347666.9375 - mae: 355.3707 - val_loss: 385263.3438 - val_mae: 379.3075\n",
      "Epoch 248/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 387907.5000 - mae: 372.4315 - val_loss: 389159.4688 - val_mae: 380.7598\n",
      "Epoch 249/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 331830.1875 - mae: 353.6334 - val_loss: 385948.2500 - val_mae: 379.6080\n",
      "Epoch 250/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 367505.1250 - mae: 356.9355 - val_loss: 388065.8125 - val_mae: 380.2590\n",
      "Epoch 251/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 374011.7812 - mae: 366.7020 - val_loss: 385439.4062 - val_mae: 378.7139\n",
      "Epoch 252/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 393543.4375 - mae: 382.1275 - val_loss: 386346.5312 - val_mae: 379.5297\n",
      "Epoch 253/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 355333.6562 - mae: 354.5064 - val_loss: 387019.6562 - val_mae: 379.7887\n",
      "Epoch 254/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 357299.1875 - mae: 366.6086 - val_loss: 387244.3438 - val_mae: 380.7290\n",
      "Epoch 255/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 305962.5000 - mae: 341.4459 - val_loss: 386248.9062 - val_mae: 379.6200\n",
      "Epoch 256/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 317575.2812 - mae: 352.7155 - val_loss: 386741.3125 - val_mae: 379.8753\n",
      "Epoch 257/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 324803.0312 - mae: 356.8817 - val_loss: 386427.2812 - val_mae: 379.3859\n",
      "Epoch 258/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 356320.6875 - mae: 362.8136 - val_loss: 383853.5000 - val_mae: 377.4130\n",
      "Epoch 259/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 303972.4375 - mae: 334.2526 - val_loss: 383853.9375 - val_mae: 378.3229\n",
      "Epoch 260/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 361966.0625 - mae: 357.7408 - val_loss: 382323.8438 - val_mae: 376.6114\n",
      "Epoch 261/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 350384.5312 - mae: 355.0863 - val_loss: 383542.4688 - val_mae: 378.7798\n",
      "Epoch 262/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 345992.5312 - mae: 360.0358 - val_loss: 386054.9375 - val_mae: 379.6461\n",
      "Epoch 263/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 367378.0625 - mae: 364.3721 - val_loss: 386544.3125 - val_mae: 379.4980\n",
      "Epoch 264/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 375708.5000 - mae: 376.1538 - val_loss: 385830.6250 - val_mae: 379.3091\n",
      "Epoch 265/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 323736.9062 - mae: 348.7431 - val_loss: 381650.7188 - val_mae: 375.7553\n",
      "Epoch 266/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 320152.7500 - mae: 340.0671 - val_loss: 385525.6562 - val_mae: 378.2988\n",
      "Epoch 267/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 351296.5938 - mae: 357.8297 - val_loss: 382458.5000 - val_mae: 376.5930\n",
      "Epoch 268/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 320079.3438 - mae: 343.8364 - val_loss: 384557.0625 - val_mae: 378.2369\n",
      "Epoch 269/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 339780.2188 - mae: 349.5039 - val_loss: 386250.5312 - val_mae: 378.8524\n",
      "Epoch 270/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 390067.5625 - mae: 370.2174 - val_loss: 383246.1875 - val_mae: 377.4832\n",
      "Epoch 271/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 370748.4062 - mae: 355.0403 - val_loss: 383997.8438 - val_mae: 377.6635\n",
      "Epoch 272/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 360327.9375 - mae: 360.7418 - val_loss: 381654.2500 - val_mae: 375.8158\n",
      "Epoch 273/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 353987.1562 - mae: 356.4220 - val_loss: 381952.0625 - val_mae: 376.3152\n",
      "Epoch 274/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 296902.7812 - mae: 335.7132 - val_loss: 379220.1875 - val_mae: 374.3864\n",
      "Epoch 275/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 309275.6250 - mae: 340.5103 - val_loss: 383798.4375 - val_mae: 377.7392\n",
      "Epoch 276/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 349531.4062 - mae: 354.8986 - val_loss: 382764.3438 - val_mae: 376.2914\n",
      "Epoch 277/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 328686.9375 - mae: 343.8855 - val_loss: 379668.9688 - val_mae: 374.3567\n",
      "Epoch 278/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 366419.9062 - mae: 352.7589 - val_loss: 381636.5312 - val_mae: 376.0932\n",
      "Epoch 279/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 381928.0312 - mae: 378.8160 - val_loss: 381081.5938 - val_mae: 375.3015\n",
      "Epoch 280/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 381321.6562 - mae: 367.7206 - val_loss: 380139.1562 - val_mae: 374.7161\n",
      "Epoch 281/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 356870.5625 - mae: 361.3062 - val_loss: 383620.0000 - val_mae: 377.0643\n",
      "Epoch 282/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 356689.6562 - mae: 353.8597 - val_loss: 380877.8125 - val_mae: 375.4365\n",
      "Epoch 283/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 313296.4062 - mae: 332.1204 - val_loss: 384176.7812 - val_mae: 377.6623\n",
      "Epoch 284/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 370122.6562 - mae: 357.3826 - val_loss: 382467.1562 - val_mae: 376.6535\n",
      "Epoch 285/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318909.2500 - mae: 332.3186 - val_loss: 379058.3125 - val_mae: 374.5761\n",
      "Epoch 286/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 390856.6875 - mae: 381.1454 - val_loss: 379101.8750 - val_mae: 374.1232\n",
      "Epoch 287/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 332688.6562 - mae: 341.3023 - val_loss: 382799.4688 - val_mae: 376.7372\n",
      "Epoch 288/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 300567.2812 - mae: 330.7101 - val_loss: 380634.2500 - val_mae: 375.6805\n",
      "Epoch 289/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 318903.9375 - mae: 346.1095 - val_loss: 380755.7812 - val_mae: 374.9116\n",
      "Epoch 290/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 355896.5312 - mae: 352.4735 - val_loss: 377899.6250 - val_mae: 373.2211\n",
      "Epoch 291/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 327978.7812 - mae: 351.1249 - val_loss: 383488.5625 - val_mae: 378.1854\n",
      "Epoch 292/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 361353.0938 - mae: 360.1662 - val_loss: 380345.5000 - val_mae: 375.0653\n",
      "Epoch 293/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 324685.2812 - mae: 341.4148 - val_loss: 383534.6250 - val_mae: 377.2227\n",
      "Epoch 294/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 346281.3438 - mae: 351.4010 - val_loss: 381140.5938 - val_mae: 375.4755\n",
      "Epoch 295/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 303269.0000 - mae: 335.9993 - val_loss: 378962.7500 - val_mae: 374.5008\n",
      "Epoch 296/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 355456.8750 - mae: 353.1670 - val_loss: 382036.5938 - val_mae: 375.9414\n",
      "Epoch 297/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 342157.4062 - mae: 352.2390 - val_loss: 380350.5000 - val_mae: 375.1710\n",
      "Epoch 298/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 365718.2812 - mae: 359.2294 - val_loss: 376110.0312 - val_mae: 371.9837\n",
      "Epoch 299/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 340617.7188 - mae: 361.8474 - val_loss: 381197.0312 - val_mae: 376.0768\n",
      "Epoch 300/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 324426.1562 - mae: 353.0625 - val_loss: 379193.3750 - val_mae: 374.9537\n",
      "Epoch 301/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 325167.7500 - mae: 353.3400 - val_loss: 380044.8438 - val_mae: 374.9586\n",
      "Epoch 302/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 318502.0312 - mae: 338.4018 - val_loss: 379427.6562 - val_mae: 375.0627\n",
      "Epoch 303/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 357032.7500 - mae: 366.0481 - val_loss: 380689.5625 - val_mae: 375.3102\n",
      "Epoch 304/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 361470.3750 - mae: 351.0609 - val_loss: 377263.0312 - val_mae: 372.9612\n",
      "Epoch 305/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 365735.2500 - mae: 370.5707 - val_loss: 380117.6562 - val_mae: 374.9899\n",
      "Epoch 306/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 407256.4375 - mae: 365.8397 - val_loss: 378076.9062 - val_mae: 372.9789\n",
      "Epoch 307/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 344920.0625 - mae: 347.9014 - val_loss: 376306.9688 - val_mae: 372.1555\n",
      "Epoch 308/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 331635.3750 - mae: 339.0421 - val_loss: 379404.2500 - val_mae: 374.5542\n",
      "Epoch 309/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 312633.8750 - mae: 339.9112 - val_loss: 376352.5000 - val_mae: 372.5378\n",
      "Epoch 310/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 363017.3750 - mae: 350.4868 - val_loss: 378183.2812 - val_mae: 373.7471\n",
      "Epoch 311/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 332698.9688 - mae: 347.1558 - val_loss: 377377.5000 - val_mae: 372.9289\n",
      "Epoch 312/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 344051.3125 - mae: 355.4214 - val_loss: 377047.8125 - val_mae: 372.2180\n",
      "Epoch 313/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 361639.3125 - mae: 362.8522 - val_loss: 379283.8438 - val_mae: 374.1772\n",
      "Epoch 314/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 380694.2812 - mae: 360.7430 - val_loss: 377276.0625 - val_mae: 373.2748\n",
      "Epoch 315/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 368161.0938 - mae: 363.7796 - val_loss: 379112.1250 - val_mae: 374.6622\n",
      "Epoch 316/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 341555.8750 - mae: 351.8986 - val_loss: 377903.6562 - val_mae: 373.4134\n",
      "Epoch 317/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 387086.9688 - mae: 369.3882 - val_loss: 379185.9062 - val_mae: 374.4199\n",
      "Epoch 318/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 370413.0000 - mae: 369.5532 - val_loss: 379069.9688 - val_mae: 374.1380\n",
      "Epoch 319/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 334657.6562 - mae: 353.3711 - val_loss: 375813.9062 - val_mae: 372.1555\n",
      "Epoch 320/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 311026.0000 - mae: 336.1577 - val_loss: 378368.7812 - val_mae: 373.8875\n",
      "Epoch 321/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 345281.4375 - mae: 346.7824 - val_loss: 379085.0312 - val_mae: 373.8882\n",
      "Epoch 322/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 344343.2188 - mae: 341.9563 - val_loss: 377018.1250 - val_mae: 373.3947\n",
      "Epoch 323/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 380900.0625 - mae: 367.6435 - val_loss: 377760.5000 - val_mae: 373.6113\n",
      "Epoch 324/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 334479.6562 - mae: 361.7942 - val_loss: 376860.0625 - val_mae: 372.7329\n",
      "Epoch 325/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 295600.5312 - mae: 330.0928 - val_loss: 375086.5938 - val_mae: 370.8925\n",
      "Epoch 326/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 388356.5000 - mae: 376.0037 - val_loss: 376002.6562 - val_mae: 371.9097\n",
      "Epoch 327/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 305467.8750 - mae: 339.5457 - val_loss: 375213.9375 - val_mae: 371.5424\n",
      "Epoch 328/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 293009.0938 - mae: 331.7765 - val_loss: 376341.7500 - val_mae: 372.9225\n",
      "Epoch 329/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 344340.7812 - mae: 357.7885 - val_loss: 375950.8438 - val_mae: 371.9960\n",
      "Epoch 330/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 365169.9375 - mae: 355.3528 - val_loss: 375165.1250 - val_mae: 371.3647\n",
      "Epoch 331/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 334869.8750 - mae: 341.5914 - val_loss: 374787.3750 - val_mae: 370.6901\n",
      "Epoch 332/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 338812.9062 - mae: 346.5045 - val_loss: 375023.1875 - val_mae: 372.1209\n",
      "Epoch 333/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 346488.2500 - mae: 352.8867 - val_loss: 374770.6875 - val_mae: 371.4607\n",
      "Epoch 334/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 333656.5000 - mae: 344.7672 - val_loss: 375918.7500 - val_mae: 372.4632\n",
      "Epoch 335/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 302827.2812 - mae: 338.1376 - val_loss: 375141.6875 - val_mae: 372.2018\n",
      "Epoch 336/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 360081.4688 - mae: 365.1139 - val_loss: 374919.0625 - val_mae: 372.2219\n",
      "Epoch 337/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 364079.1250 - mae: 363.5601 - val_loss: 374918.9375 - val_mae: 371.7945\n",
      "Epoch 338/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 413933.1562 - mae: 383.9054 - val_loss: 375516.5000 - val_mae: 372.4670\n",
      "Epoch 339/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 318310.8438 - mae: 335.2916 - val_loss: 374140.9688 - val_mae: 370.8964\n",
      "Epoch 340/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 354093.6562 - mae: 351.4657 - val_loss: 373517.5938 - val_mae: 371.0204\n",
      "Epoch 341/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 323318.3125 - mae: 342.7262 - val_loss: 371891.8750 - val_mae: 369.3827\n",
      "Epoch 342/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 352348.9688 - mae: 357.0063 - val_loss: 374735.0312 - val_mae: 371.8852\n",
      "Epoch 343/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 342961.2188 - mae: 345.4040 - val_loss: 376172.3125 - val_mae: 372.3079\n",
      "Epoch 344/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 334546.7812 - mae: 345.3899 - val_loss: 374292.7188 - val_mae: 371.0753\n",
      "Epoch 345/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 341868.5625 - mae: 346.6292 - val_loss: 377459.0312 - val_mae: 373.8116\n",
      "Epoch 346/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 304646.7500 - mae: 334.7622 - val_loss: 372622.4375 - val_mae: 369.9683\n",
      "Epoch 347/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 349241.3438 - mae: 356.7646 - val_loss: 374513.7812 - val_mae: 371.5706\n",
      "Epoch 348/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 345539.4688 - mae: 347.2984 - val_loss: 373238.9688 - val_mae: 370.2140\n",
      "Epoch 349/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 324684.7812 - mae: 330.8329 - val_loss: 373640.4688 - val_mae: 370.6474\n",
      "Epoch 350/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 377014.1875 - mae: 359.8995 - val_loss: 373878.8438 - val_mae: 370.2848\n",
      "Epoch 351/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 353466.3438 - mae: 343.8335 - val_loss: 373821.7812 - val_mae: 370.8819\n",
      "Epoch 352/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 318737.3125 - mae: 345.2678 - val_loss: 378596.1875 - val_mae: 374.8987\n",
      "Epoch 353/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 319532.4375 - mae: 348.8979 - val_loss: 376035.6250 - val_mae: 372.3516\n",
      "Epoch 354/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 316886.6250 - mae: 343.0200 - val_loss: 374564.7188 - val_mae: 370.8469\n",
      "Epoch 355/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 334782.3438 - mae: 337.4332 - val_loss: 373838.2812 - val_mae: 370.6649\n",
      "Epoch 356/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 328566.0312 - mae: 341.1134 - val_loss: 372720.0000 - val_mae: 369.7578\n",
      "Epoch 357/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 335062.0000 - mae: 352.2025 - val_loss: 373151.8125 - val_mae: 370.0783\n",
      "Epoch 358/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 407518.4688 - mae: 377.5732 - val_loss: 371771.8438 - val_mae: 368.7691\n",
      "Epoch 359/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 336550.2500 - mae: 347.4213 - val_loss: 375218.9375 - val_mae: 371.5724\n",
      "Epoch 360/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 329473.5625 - mae: 350.1083 - val_loss: 372159.8125 - val_mae: 368.8313\n",
      "Epoch 361/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 311161.5000 - mae: 336.3633 - val_loss: 373625.3438 - val_mae: 370.9131\n",
      "Epoch 362/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 321090.2188 - mae: 347.2233 - val_loss: 378841.3125 - val_mae: 373.7014\n",
      "Epoch 363/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 377959.0938 - mae: 366.8806 - val_loss: 370996.0938 - val_mae: 368.2366\n",
      "Epoch 364/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 305371.9375 - mae: 334.6710 - val_loss: 374068.1250 - val_mae: 370.6769\n",
      "Epoch 365/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 364514.6250 - mae: 358.4424 - val_loss: 375456.5938 - val_mae: 371.6092\n",
      "Epoch 366/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 316584.0000 - mae: 343.0916 - val_loss: 373213.7812 - val_mae: 370.0418\n",
      "Epoch 367/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 353261.2500 - mae: 350.6272 - val_loss: 374006.8750 - val_mae: 370.9142\n",
      "Epoch 368/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 352404.0938 - mae: 354.8967 - val_loss: 373054.2500 - val_mae: 370.1659\n",
      "Epoch 369/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 318172.3750 - mae: 346.6281 - val_loss: 373701.3750 - val_mae: 370.4309\n",
      "Epoch 370/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 331499.3125 - mae: 339.6930 - val_loss: 375884.0312 - val_mae: 371.5779\n",
      "Epoch 371/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 369116.4375 - mae: 364.3598 - val_loss: 373995.1562 - val_mae: 370.2115\n",
      "Epoch 372/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 286930.1250 - mae: 324.8022 - val_loss: 372256.4688 - val_mae: 369.2777\n",
      "Epoch 373/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 348816.7500 - mae: 349.9019 - val_loss: 376757.3750 - val_mae: 372.5616\n",
      "Epoch 374/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 347800.3438 - mae: 350.0837 - val_loss: 371541.8125 - val_mae: 369.5322\n",
      "Epoch 375/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 316349.0000 - mae: 337.3310 - val_loss: 372912.9062 - val_mae: 369.9271\n",
      "Epoch 376/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 322019.0000 - mae: 342.6744 - val_loss: 374870.4062 - val_mae: 370.7681\n",
      "Epoch 377/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 367674.0312 - mae: 360.8492 - val_loss: 371509.3750 - val_mae: 368.1944\n",
      "Epoch 378/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 318526.8438 - mae: 340.6116 - val_loss: 373644.3750 - val_mae: 370.6798\n",
      "Epoch 379/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 346239.3750 - mae: 350.4716 - val_loss: 372628.9688 - val_mae: 369.2971\n",
      "Epoch 380/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 329592.7500 - mae: 344.9435 - val_loss: 374715.0938 - val_mae: 370.5682\n",
      "Epoch 381/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 309632.5312 - mae: 336.1374 - val_loss: 374968.0625 - val_mae: 370.2876\n",
      "Epoch 382/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 343221.4062 - mae: 340.3320 - val_loss: 373035.6250 - val_mae: 369.0424\n",
      "Epoch 383/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 327355.5938 - mae: 349.9235 - val_loss: 372499.9688 - val_mae: 368.9625\n",
      "Epoch 384/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 304025.6875 - mae: 341.8848 - val_loss: 376088.5625 - val_mae: 371.7112\n",
      "Epoch 385/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 384640.1875 - mae: 359.1851 - val_loss: 372872.5938 - val_mae: 368.9132\n",
      "Epoch 386/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 338026.9688 - mae: 355.2934 - val_loss: 371046.4062 - val_mae: 367.8223\n",
      "Epoch 387/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 359100.2188 - mae: 354.7560 - val_loss: 371640.1875 - val_mae: 367.7184\n",
      "Epoch 388/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 366085.4688 - mae: 358.1793 - val_loss: 369152.5938 - val_mae: 366.5516\n",
      "Epoch 389/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 338311.0938 - mae: 346.8329 - val_loss: 370333.3750 - val_mae: 367.3161\n",
      "Epoch 390/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 307755.1562 - mae: 336.2413 - val_loss: 374684.5625 - val_mae: 370.6000\n",
      "Epoch 391/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 365850.2812 - mae: 367.0139 - val_loss: 370406.4062 - val_mae: 367.3195\n",
      "Epoch 392/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 298938.1562 - mae: 336.4459 - val_loss: 372371.2188 - val_mae: 368.0997\n",
      "Epoch 393/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 330664.8438 - mae: 344.9851 - val_loss: 377077.3438 - val_mae: 371.6496\n",
      "Epoch 394/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 300482.0625 - mae: 332.7807 - val_loss: 372006.0000 - val_mae: 368.3317\n",
      "Epoch 395/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 311817.0938 - mae: 342.3977 - val_loss: 372675.0938 - val_mae: 368.0730\n",
      "Epoch 396/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 313817.5938 - mae: 332.5058 - val_loss: 375008.3438 - val_mae: 370.3844\n",
      "Epoch 397/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 295607.1250 - mae: 332.9345 - val_loss: 370918.2500 - val_mae: 367.5187\n",
      "Epoch 398/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 342926.5000 - mae: 348.1822 - val_loss: 372457.9062 - val_mae: 367.9077\n",
      "Epoch 399/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 323089.1875 - mae: 353.4398 - val_loss: 372016.3125 - val_mae: 367.8373\n",
      "Epoch 400/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 334225.7188 - mae: 338.0329 - val_loss: 371995.7500 - val_mae: 367.7776\n",
      "Epoch 401/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 322889.3125 - mae: 338.4646 - val_loss: 370483.9688 - val_mae: 366.9326\n",
      "Epoch 402/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 310671.0000 - mae: 328.4775 - val_loss: 373069.5625 - val_mae: 367.8021\n",
      "Epoch 403/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 361181.4688 - mae: 354.3523 - val_loss: 370235.0312 - val_mae: 366.5033\n",
      "Epoch 404/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 407084.9375 - mae: 372.5995 - val_loss: 369831.1250 - val_mae: 365.4237\n",
      "Epoch 405/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 396966.6250 - mae: 365.7375 - val_loss: 368936.9062 - val_mae: 366.1006\n",
      "Epoch 406/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 305793.6250 - mae: 332.3369 - val_loss: 372618.0000 - val_mae: 367.8964\n",
      "Epoch 407/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 355191.0938 - mae: 345.1344 - val_loss: 372204.1250 - val_mae: 367.1760\n",
      "Epoch 408/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 309113.4375 - mae: 335.1317 - val_loss: 371295.3125 - val_mae: 366.9124\n",
      "Epoch 409/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 351912.0625 - mae: 366.3150 - val_loss: 369527.5625 - val_mae: 365.8275\n",
      "Epoch 410/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 356147.7500 - mae: 358.4344 - val_loss: 370424.4062 - val_mae: 367.0815\n",
      "Epoch 411/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 303658.4375 - mae: 330.1088 - val_loss: 370586.6250 - val_mae: 366.1076\n",
      "Epoch 412/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 319442.2188 - mae: 342.2315 - val_loss: 370355.6562 - val_mae: 366.3412\n",
      "Epoch 413/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 296806.3438 - mae: 327.0305 - val_loss: 372231.1562 - val_mae: 367.3709\n",
      "Epoch 414/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 332355.7812 - mae: 341.6362 - val_loss: 373378.2188 - val_mae: 368.0154\n",
      "Epoch 415/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 337126.9688 - mae: 345.6043 - val_loss: 371990.1562 - val_mae: 367.6819\n",
      "Epoch 416/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 300652.5000 - mae: 335.1539 - val_loss: 371428.9375 - val_mae: 367.4933\n",
      "Epoch 417/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 332046.5312 - mae: 338.6412 - val_loss: 371159.9688 - val_mae: 366.4753\n",
      "Epoch 418/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 278159.4375 - mae: 322.7098 - val_loss: 371782.9688 - val_mae: 366.1003\n",
      "Epoch 419/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 341274.5312 - mae: 346.7513 - val_loss: 372566.8438 - val_mae: 367.2462\n",
      "Epoch 420/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 332231.6562 - mae: 354.2924 - val_loss: 371030.1250 - val_mae: 366.4752\n",
      "Epoch 421/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 312692.1875 - mae: 336.7722 - val_loss: 371747.6562 - val_mae: 366.3033\n",
      "Epoch 422/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 339009.7188 - mae: 350.2162 - val_loss: 369139.0000 - val_mae: 365.1088\n",
      "Epoch 423/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 305157.9688 - mae: 326.6812 - val_loss: 373235.2500 - val_mae: 368.1906\n",
      "Epoch 424/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 306852.5312 - mae: 333.7111 - val_loss: 369002.2812 - val_mae: 365.1289\n",
      "Epoch 425/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 301241.9688 - mae: 335.4677 - val_loss: 373205.1875 - val_mae: 366.8955\n",
      "Epoch 426/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 306691.0312 - mae: 336.7548 - val_loss: 372349.5625 - val_mae: 367.1598\n",
      "Epoch 427/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 341695.2812 - mae: 346.5985 - val_loss: 370156.0312 - val_mae: 365.5972\n",
      "Epoch 428/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 332030.7812 - mae: 343.7440 - val_loss: 368936.8750 - val_mae: 364.9555\n",
      "Epoch 429/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 302550.6250 - mae: 330.1213 - val_loss: 366956.7500 - val_mae: 363.0505\n",
      "Epoch 430/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 334696.8125 - mae: 348.7273 - val_loss: 370234.6250 - val_mae: 365.3649\n",
      "Epoch 431/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 345330.8438 - mae: 346.8935 - val_loss: 374010.1250 - val_mae: 368.0820\n",
      "Epoch 432/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 331627.6250 - mae: 344.1064 - val_loss: 369886.0938 - val_mae: 365.1706\n",
      "Epoch 433/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 354718.7500 - mae: 357.5882 - val_loss: 368724.6562 - val_mae: 363.9199\n",
      "Epoch 434/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 339703.1562 - mae: 333.8601 - val_loss: 370009.1250 - val_mae: 364.3395\n",
      "Epoch 435/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 310489.6562 - mae: 341.0226 - val_loss: 373612.0312 - val_mae: 367.7439\n",
      "Epoch 436/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 326797.4375 - mae: 340.3029 - val_loss: 369184.2812 - val_mae: 364.8988\n",
      "Epoch 437/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 324273.6250 - mae: 336.6592 - val_loss: 371189.5000 - val_mae: 365.5974\n",
      "Epoch 438/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 331963.1562 - mae: 345.1991 - val_loss: 370318.7812 - val_mae: 364.7795\n",
      "Epoch 439/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 332596.1562 - mae: 339.7920 - val_loss: 371832.5625 - val_mae: 366.1724\n",
      "Epoch 440/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 356817.8438 - mae: 355.1745 - val_loss: 368887.4062 - val_mae: 364.0668\n",
      "Epoch 441/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 311445.3750 - mae: 336.7652 - val_loss: 368666.0000 - val_mae: 363.1568\n",
      "Epoch 442/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 372043.1875 - mae: 356.8705 - val_loss: 370651.0938 - val_mae: 365.3346\n",
      "Epoch 443/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 311613.3438 - mae: 333.1491 - val_loss: 371973.9062 - val_mae: 365.4677\n",
      "Epoch 444/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 297992.5312 - mae: 325.7719 - val_loss: 372093.6250 - val_mae: 366.4685\n",
      "Epoch 445/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 294662.0000 - mae: 337.6824 - val_loss: 375446.9375 - val_mae: 368.2917\n",
      "Epoch 446/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 314985.8438 - mae: 324.9255 - val_loss: 373532.5312 - val_mae: 366.8593\n",
      "Epoch 447/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 295036.4688 - mae: 325.1023 - val_loss: 369487.3438 - val_mae: 363.8493\n",
      "Epoch 448/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 303056.2812 - mae: 331.3092 - val_loss: 368746.7812 - val_mae: 363.8669\n",
      "Epoch 449/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 326035.4375 - mae: 336.6939 - val_loss: 367374.9688 - val_mae: 363.3070\n",
      "Epoch 450/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 318179.1875 - mae: 336.1158 - val_loss: 368471.0312 - val_mae: 364.5023\n",
      "Epoch 451/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 298924.6250 - mae: 329.4022 - val_loss: 372322.5312 - val_mae: 365.2358\n",
      "Epoch 452/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 318198.8750 - mae: 335.4168 - val_loss: 372531.5938 - val_mae: 365.4868\n",
      "Epoch 453/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 323485.6562 - mae: 348.1554 - val_loss: 368708.1250 - val_mae: 364.1751\n",
      "Epoch 454/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 361530.0000 - mae: 348.9003 - val_loss: 368571.0312 - val_mae: 363.5736\n",
      "Epoch 455/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 322801.9062 - mae: 342.0657 - val_loss: 368392.0938 - val_mae: 362.9241\n",
      "Epoch 456/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 310658.3438 - mae: 336.6158 - val_loss: 368010.1250 - val_mae: 363.6074\n",
      "Epoch 457/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 362424.4375 - mae: 347.8723 - val_loss: 371768.9375 - val_mae: 366.0363\n",
      "Epoch 458/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 306600.6562 - mae: 323.7989 - val_loss: 371306.9375 - val_mae: 365.4684\n",
      "Epoch 459/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 332352.4375 - mae: 344.2788 - val_loss: 370756.2188 - val_mae: 364.8794\n",
      "Epoch 460/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 364456.3438 - mae: 355.2124 - val_loss: 369391.3125 - val_mae: 362.4908\n",
      "Epoch 461/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 316827.9375 - mae: 334.0147 - val_loss: 373586.6875 - val_mae: 366.8038\n",
      "Epoch 462/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 324928.2500 - mae: 342.0642 - val_loss: 371524.7500 - val_mae: 365.4079\n",
      "Epoch 463/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 330019.7188 - mae: 339.1287 - val_loss: 369853.8438 - val_mae: 363.5894\n",
      "Epoch 464/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 313964.2188 - mae: 336.3622 - val_loss: 370360.2188 - val_mae: 364.4231\n",
      "Epoch 465/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 297092.2188 - mae: 328.2981 - val_loss: 371483.6562 - val_mae: 364.7656\n",
      "Epoch 466/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 256346.8750 - mae: 307.6709 - val_loss: 372728.5312 - val_mae: 365.3614\n",
      "Epoch 467/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 324092.4062 - mae: 335.4142 - val_loss: 371391.4688 - val_mae: 364.7568\n",
      "Epoch 468/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 320259.1250 - mae: 344.0299 - val_loss: 369575.5625 - val_mae: 363.6793\n",
      "Epoch 469/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 319636.4062 - mae: 331.2043 - val_loss: 371970.3125 - val_mae: 364.5021\n",
      "Epoch 470/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 310258.8125 - mae: 333.9315 - val_loss: 370843.6562 - val_mae: 364.6120\n",
      "Epoch 471/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 336220.3438 - mae: 348.0519 - val_loss: 372787.8750 - val_mae: 365.5497\n",
      "Epoch 472/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 346432.1250 - mae: 339.2480 - val_loss: 371893.1875 - val_mae: 364.7901\n",
      "Epoch 473/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 316397.9375 - mae: 331.0029 - val_loss: 371548.5625 - val_mae: 364.5762\n",
      "Epoch 474/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 302841.8125 - mae: 333.9446 - val_loss: 369533.6250 - val_mae: 363.1147\n",
      "Epoch 475/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 316222.4688 - mae: 331.7657 - val_loss: 371411.0938 - val_mae: 364.2217\n",
      "Epoch 476/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 307924.1250 - mae: 325.0626 - val_loss: 368203.8750 - val_mae: 361.8874\n",
      "Epoch 477/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 338910.0000 - mae: 341.3800 - val_loss: 372556.8438 - val_mae: 365.0132\n",
      "Epoch 478/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 346887.3125 - mae: 352.9205 - val_loss: 367213.7500 - val_mae: 361.6810\n",
      "Epoch 479/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 326915.2188 - mae: 343.5880 - val_loss: 370817.1562 - val_mae: 364.4615\n",
      "Epoch 480/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 330250.6250 - mae: 338.7429 - val_loss: 371890.6562 - val_mae: 364.4810\n",
      "Epoch 481/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 286536.2188 - mae: 321.9028 - val_loss: 370500.3438 - val_mae: 363.5933\n",
      "Epoch 482/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 327457.4062 - mae: 341.7674 - val_loss: 369265.0312 - val_mae: 363.2065\n",
      "Epoch 483/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 307901.0625 - mae: 334.6625 - val_loss: 371464.9375 - val_mae: 364.3786\n",
      "Epoch 484/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 342219.1250 - mae: 337.9622 - val_loss: 370236.7500 - val_mae: 363.4578\n",
      "Epoch 485/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 303767.3125 - mae: 329.5889 - val_loss: 371295.9688 - val_mae: 364.3119\n",
      "Epoch 486/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 331430.2500 - mae: 344.9709 - val_loss: 370984.6875 - val_mae: 364.0353\n",
      "Epoch 487/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 289780.8125 - mae: 321.2266 - val_loss: 369734.1875 - val_mae: 363.2430\n",
      "Epoch 488/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 344939.1562 - mae: 342.7479 - val_loss: 370004.0312 - val_mae: 363.7796\n",
      "Epoch 489/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 342736.2188 - mae: 344.3054 - val_loss: 369171.6875 - val_mae: 363.0142\n",
      "Epoch 490/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 298363.1250 - mae: 322.8756 - val_loss: 370373.2500 - val_mae: 363.5979\n",
      "Epoch 491/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 340623.0938 - mae: 347.2992 - val_loss: 370098.1250 - val_mae: 362.6114\n",
      "Epoch 492/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 318455.4375 - mae: 333.4650 - val_loss: 371450.9375 - val_mae: 363.8828\n",
      "Epoch 493/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 326506.0625 - mae: 337.2000 - val_loss: 370100.3438 - val_mae: 362.8036\n",
      "Epoch 494/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 326314.1250 - mae: 336.0870 - val_loss: 368223.2500 - val_mae: 361.0680\n",
      "Epoch 495/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 330748.5625 - mae: 343.5103 - val_loss: 370826.0312 - val_mae: 363.5885\n",
      "Epoch 496/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 314544.3438 - mae: 333.7931 - val_loss: 370528.9062 - val_mae: 363.8763\n",
      "Epoch 497/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 339758.8438 - mae: 342.3282 - val_loss: 369844.0938 - val_mae: 362.3994\n",
      "Epoch 498/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 302471.9062 - mae: 321.1928 - val_loss: 369932.0938 - val_mae: 362.7733\n",
      "Epoch 499/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 337271.4688 - mae: 346.7799 - val_loss: 369450.3438 - val_mae: 361.9590\n",
      "Epoch 500/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 312613.1250 - mae: 322.1986 - val_loss: 371473.0625 - val_mae: 364.0206\n",
      "Epoch 501/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331246.6875 - mae: 344.2154 - val_loss: 371268.0000 - val_mae: 362.9663\n",
      "Epoch 502/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 360997.8125 - mae: 344.2880 - val_loss: 369561.0938 - val_mae: 362.5190\n",
      "Epoch 503/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 351771.8438 - mae: 351.5729 - val_loss: 371137.5625 - val_mae: 363.6153\n",
      "Epoch 504/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 348894.3125 - mae: 352.1617 - val_loss: 366256.6875 - val_mae: 360.6618\n",
      "Epoch 505/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 321474.9062 - mae: 340.0898 - val_loss: 369055.3438 - val_mae: 361.9866\n",
      "Epoch 506/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 310692.5312 - mae: 328.7956 - val_loss: 372018.6875 - val_mae: 364.3699\n",
      "Epoch 507/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 305067.8438 - mae: 330.6311 - val_loss: 369624.9375 - val_mae: 362.8233\n",
      "Epoch 508/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 301742.6562 - mae: 331.1033 - val_loss: 371241.8125 - val_mae: 364.0256\n",
      "Epoch 509/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 318804.6250 - mae: 333.7941 - val_loss: 369628.0312 - val_mae: 362.1280\n",
      "Epoch 510/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 319428.3750 - mae: 332.4746 - val_loss: 374150.0938 - val_mae: 365.8222\n",
      "Epoch 511/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 284000.2500 - mae: 323.7173 - val_loss: 369787.9062 - val_mae: 361.9252\n",
      "Epoch 512/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 333317.2812 - mae: 342.0628 - val_loss: 370838.9062 - val_mae: 363.1223\n",
      "Epoch 513/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 336340.2500 - mae: 342.8734 - val_loss: 370034.1250 - val_mae: 362.7321\n",
      "Epoch 514/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 362688.3438 - mae: 346.2323 - val_loss: 368992.7500 - val_mae: 361.1921\n",
      "Epoch 515/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 291351.4688 - mae: 327.3524 - val_loss: 370292.3750 - val_mae: 363.1594\n",
      "Epoch 516/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 318545.1250 - mae: 337.4214 - val_loss: 367926.8125 - val_mae: 360.8404\n",
      "Epoch 517/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 334531.0000 - mae: 337.6443 - val_loss: 368154.5000 - val_mae: 361.4178\n",
      "Epoch 518/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 294648.4688 - mae: 324.9002 - val_loss: 367942.9688 - val_mae: 360.5368\n",
      "Epoch 519/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 341144.5312 - mae: 343.5370 - val_loss: 368060.2812 - val_mae: 360.3863\n",
      "Epoch 520/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 299080.1875 - mae: 327.3759 - val_loss: 371847.3750 - val_mae: 363.1771\n",
      "Epoch 521/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 296493.0625 - mae: 333.6019 - val_loss: 371608.0625 - val_mae: 363.3159\n",
      "Epoch 522/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 337071.5312 - mae: 335.7340 - val_loss: 369994.3750 - val_mae: 362.8282\n",
      "Epoch 523/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 288577.8750 - mae: 321.9504 - val_loss: 374183.1562 - val_mae: 365.2854\n",
      "Epoch 524/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 285449.7188 - mae: 313.1562 - val_loss: 373123.5000 - val_mae: 364.5861\n",
      "Epoch 525/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 305404.2812 - mae: 331.0041 - val_loss: 368447.9375 - val_mae: 360.9293\n",
      "Epoch 526/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 309210.4062 - mae: 328.7055 - val_loss: 372690.1875 - val_mae: 364.5750\n",
      "Epoch 527/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 335905.0938 - mae: 347.2831 - val_loss: 372103.5312 - val_mae: 364.0798\n",
      "Epoch 528/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 329155.4375 - mae: 333.2357 - val_loss: 369130.1875 - val_mae: 361.5943\n",
      "Epoch 529/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 326063.6875 - mae: 345.4167 - val_loss: 369822.3125 - val_mae: 362.0573\n",
      "Epoch 530/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 319488.0000 - mae: 331.1694 - val_loss: 369800.8750 - val_mae: 362.0182\n",
      "Epoch 531/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 340685.5938 - mae: 345.9226 - val_loss: 371908.8438 - val_mae: 363.4863\n",
      "Epoch 532/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 342271.0000 - mae: 335.2268 - val_loss: 369083.6562 - val_mae: 362.0091\n",
      "Epoch 533/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 351154.5938 - mae: 352.3173 - val_loss: 370258.9688 - val_mae: 362.1897\n",
      "Epoch 534/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 327277.4375 - mae: 342.1280 - val_loss: 370399.5625 - val_mae: 362.4369\n",
      "Epoch 535/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 303863.1562 - mae: 322.7198 - val_loss: 371309.4688 - val_mae: 363.1122\n",
      "Epoch 536/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 338231.9062 - mae: 332.1648 - val_loss: 370585.2812 - val_mae: 363.1524\n",
      "Epoch 537/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 273240.2500 - mae: 309.7067 - val_loss: 369809.8125 - val_mae: 361.8220\n",
      "Epoch 538/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 306568.0625 - mae: 321.0930 - val_loss: 373769.6875 - val_mae: 365.3161\n",
      "Epoch 539/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 339491.7188 - mae: 337.3603 - val_loss: 370879.1562 - val_mae: 363.1205\n",
      "Epoch 540/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 288332.2500 - mae: 333.1866 - val_loss: 372779.1562 - val_mae: 364.1288\n",
      "Epoch 541/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 307205.3750 - mae: 327.6663 - val_loss: 373270.1562 - val_mae: 365.1518\n",
      "Epoch 542/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 311084.9375 - mae: 318.0126 - val_loss: 370958.8750 - val_mae: 363.2824\n",
      "Epoch 543/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 352904.7500 - mae: 345.6434 - val_loss: 370531.2500 - val_mae: 362.3848\n",
      "Epoch 544/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 311428.5625 - mae: 328.7834 - val_loss: 372443.5625 - val_mae: 363.4034\n",
      "Epoch 545/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 351680.1875 - mae: 343.9790 - val_loss: 370707.0000 - val_mae: 361.8199\n",
      "Epoch 546/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 327784.5938 - mae: 329.6862 - val_loss: 370971.9062 - val_mae: 362.4851\n",
      "Epoch 547/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 294788.7812 - mae: 325.3810 - val_loss: 369618.1875 - val_mae: 362.0512\n",
      "Epoch 548/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 339893.5312 - mae: 343.1461 - val_loss: 370716.3750 - val_mae: 362.3333\n",
      "Epoch 549/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 310484.4062 - mae: 328.5023 - val_loss: 373850.7500 - val_mae: 364.4933\n",
      "Epoch 550/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 347471.8750 - mae: 351.5795 - val_loss: 368930.2812 - val_mae: 360.9949\n",
      "Epoch 551/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 315065.6562 - mae: 334.0457 - val_loss: 370765.5312 - val_mae: 362.4377\n",
      "Epoch 552/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 349774.7188 - mae: 342.5244 - val_loss: 371048.9062 - val_mae: 363.1815\n",
      "Epoch 553/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 359891.9062 - mae: 350.1205 - val_loss: 369600.0312 - val_mae: 362.5290\n",
      "Epoch 554/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 305564.0000 - mae: 338.3261 - val_loss: 374687.5000 - val_mae: 365.8256\n",
      "Epoch 555/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 315173.7812 - mae: 338.2381 - val_loss: 369024.3125 - val_mae: 361.0453\n",
      "Epoch 556/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 352504.1562 - mae: 344.5470 - val_loss: 369719.7812 - val_mae: 361.2829\n",
      "Epoch 557/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 300053.5938 - mae: 330.1310 - val_loss: 370768.9375 - val_mae: 362.8360\n",
      "Epoch 558/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 284138.2500 - mae: 313.3432 - val_loss: 369761.9688 - val_mae: 361.6593\n",
      "Epoch 559/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 336028.6875 - mae: 343.4948 - val_loss: 371834.8750 - val_mae: 363.4672\n",
      "Epoch 560/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 287793.3438 - mae: 320.6831 - val_loss: 372819.6562 - val_mae: 363.9894\n",
      "Epoch 561/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 323970.6562 - mae: 332.6300 - val_loss: 369899.9688 - val_mae: 361.4745\n",
      "Epoch 562/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 312525.4688 - mae: 331.6111 - val_loss: 373875.0312 - val_mae: 365.0130\n",
      "Epoch 563/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 321177.9688 - mae: 337.1301 - val_loss: 372645.3125 - val_mae: 363.6010\n",
      "Epoch 564/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 307875.9688 - mae: 325.0097 - val_loss: 368073.2500 - val_mae: 360.4258\n",
      "Epoch 565/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 326371.4375 - mae: 329.2547 - val_loss: 370519.4688 - val_mae: 361.6923\n",
      "Epoch 566/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 300082.0312 - mae: 329.4675 - val_loss: 371616.6562 - val_mae: 362.7311\n",
      "Epoch 567/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 335032.1250 - mae: 341.4333 - val_loss: 371362.6250 - val_mae: 362.7304\n",
      "Epoch 568/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 309185.9375 - mae: 322.6678 - val_loss: 371049.1562 - val_mae: 362.5270\n",
      "Epoch 569/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 303745.6250 - mae: 326.1681 - val_loss: 370452.3438 - val_mae: 362.4683\n",
      "Epoch 570/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 339966.5938 - mae: 342.9377 - val_loss: 372143.0312 - val_mae: 362.5297\n",
      "Epoch 571/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 343368.9688 - mae: 346.3769 - val_loss: 371388.1250 - val_mae: 362.4200\n",
      "Epoch 572/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 342993.0312 - mae: 340.0663 - val_loss: 368966.6250 - val_mae: 361.1183\n",
      "Epoch 573/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 370835.8125 - mae: 357.9203 - val_loss: 372795.2188 - val_mae: 363.9180\n",
      "Epoch 574/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 298999.2188 - mae: 320.4973 - val_loss: 374962.7812 - val_mae: 365.5950\n",
      "Epoch 575/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 370717.5938 - mae: 353.9258 - val_loss: 371529.0938 - val_mae: 362.3850\n",
      "Epoch 576/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 325134.2812 - mae: 331.5409 - val_loss: 369779.1875 - val_mae: 360.2937\n",
      "Epoch 577/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 288180.8125 - mae: 320.8086 - val_loss: 371426.0000 - val_mae: 362.2812\n",
      "Epoch 578/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 302375.3438 - mae: 326.7875 - val_loss: 373946.1875 - val_mae: 364.7353\n",
      "Epoch 579/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 292666.8125 - mae: 325.8094 - val_loss: 374168.7188 - val_mae: 364.8817\n",
      "Epoch 580/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 289406.3125 - mae: 324.6268 - val_loss: 371495.9062 - val_mae: 363.0121\n",
      "Epoch 581/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 339401.6562 - mae: 340.1897 - val_loss: 371346.2500 - val_mae: 363.2925\n",
      "Epoch 582/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 317641.4375 - mae: 332.6012 - val_loss: 371619.6875 - val_mae: 362.4815\n",
      "Epoch 583/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 317508.0312 - mae: 331.4770 - val_loss: 371031.2188 - val_mae: 362.2560\n",
      "Epoch 584/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 297875.0312 - mae: 327.2393 - val_loss: 370976.5312 - val_mae: 362.0132\n",
      "Epoch 585/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 291798.7188 - mae: 322.6258 - val_loss: 376082.4375 - val_mae: 366.2454\n",
      "Epoch 586/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 277631.0938 - mae: 323.9185 - val_loss: 369807.0312 - val_mae: 361.0445\n",
      "Epoch 587/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 353288.6562 - mae: 349.4192 - val_loss: 370971.5312 - val_mae: 362.1623\n",
      "Epoch 588/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 287062.5625 - mae: 313.6320 - val_loss: 370303.3438 - val_mae: 362.2539\n",
      "Epoch 589/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 334301.0000 - mae: 336.8538 - val_loss: 372486.8125 - val_mae: 363.1795\n",
      "Epoch 590/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 347658.7812 - mae: 351.0194 - val_loss: 371636.5938 - val_mae: 362.6686\n",
      "Epoch 591/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 320019.6875 - mae: 328.1032 - val_loss: 369680.4062 - val_mae: 361.0222\n",
      "Epoch 592/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 352865.1562 - mae: 340.0551 - val_loss: 370851.4062 - val_mae: 362.1594\n",
      "Epoch 593/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 325040.9688 - mae: 339.5973 - val_loss: 370817.7188 - val_mae: 362.4159\n",
      "Epoch 594/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 325274.4375 - mae: 336.9998 - val_loss: 371355.6250 - val_mae: 361.8033\n",
      "Epoch 595/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 312927.5625 - mae: 327.7441 - val_loss: 370780.0625 - val_mae: 362.2499\n",
      "Epoch 596/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 342935.2188 - mae: 342.9813 - val_loss: 368912.5000 - val_mae: 359.6914\n",
      "Epoch 597/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 311840.6250 - mae: 334.4033 - val_loss: 373438.5938 - val_mae: 363.9062\n",
      "Epoch 598/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 332611.5625 - mae: 344.8937 - val_loss: 370635.5625 - val_mae: 362.3240\n",
      "Epoch 599/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 280605.5625 - mae: 317.2814 - val_loss: 371195.6562 - val_mae: 362.0611\n",
      "Epoch 600/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 304488.2812 - mae: 327.2124 - val_loss: 371399.4062 - val_mae: 362.0428\n",
      "Epoch 601/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 299809.9062 - mae: 326.5254 - val_loss: 371226.0625 - val_mae: 362.7537\n",
      "Epoch 602/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 294993.7812 - mae: 323.3537 - val_loss: 369256.6875 - val_mae: 360.6017\n",
      "Epoch 603/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 331701.2812 - mae: 336.4876 - val_loss: 371092.7500 - val_mae: 362.5827\n",
      "Epoch 604/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 287885.0938 - mae: 322.2189 - val_loss: 372473.3750 - val_mae: 362.7517\n",
      "Epoch 605/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 322109.4375 - mae: 335.8728 - val_loss: 372144.8438 - val_mae: 362.2014\n",
      "Epoch 606/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 308591.5625 - mae: 323.8586 - val_loss: 372307.9062 - val_mae: 363.1108\n",
      "Epoch 607/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 278760.0000 - mae: 319.6989 - val_loss: 369555.0312 - val_mae: 361.5383\n",
      "Epoch 608/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 316232.7812 - mae: 334.0641 - val_loss: 375659.8750 - val_mae: 365.5375\n",
      "Epoch 609/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 312243.5938 - mae: 333.2372 - val_loss: 372928.5312 - val_mae: 363.3058\n",
      "Epoch 610/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 318022.2812 - mae: 325.7281 - val_loss: 370853.5938 - val_mae: 361.2391\n",
      "Epoch 611/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 318253.6562 - mae: 338.1694 - val_loss: 371663.1875 - val_mae: 362.5610\n",
      "Epoch 612/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 300651.5625 - mae: 325.1163 - val_loss: 371253.6562 - val_mae: 361.7551\n",
      "Epoch 613/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 304174.6875 - mae: 317.8410 - val_loss: 371656.9375 - val_mae: 362.1614\n",
      "Epoch 614/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 272870.2500 - mae: 308.6454 - val_loss: 369804.7500 - val_mae: 360.8481\n",
      "Epoch 615/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 323955.3125 - mae: 339.5417 - val_loss: 370497.1875 - val_mae: 361.8567\n",
      "Epoch 616/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 345878.4688 - mae: 345.7813 - val_loss: 374259.5312 - val_mae: 364.2703\n",
      "Epoch 617/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 320772.2812 - mae: 339.2461 - val_loss: 375090.1562 - val_mae: 365.0779\n",
      "Epoch 618/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 316787.9688 - mae: 331.5015 - val_loss: 370936.5312 - val_mae: 361.2265\n",
      "Epoch 619/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 305083.5000 - mae: 324.2360 - val_loss: 373092.1875 - val_mae: 363.9788\n",
      "Epoch 620/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 317965.7188 - mae: 341.1413 - val_loss: 370341.5625 - val_mae: 360.8857\n",
      "Epoch 621/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 317847.0625 - mae: 325.3913 - val_loss: 372738.0625 - val_mae: 362.4059\n",
      "Epoch 622/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 297963.0625 - mae: 324.5871 - val_loss: 370950.8125 - val_mae: 361.8346\n",
      "Epoch 623/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 302986.3750 - mae: 317.6280 - val_loss: 372004.0000 - val_mae: 361.6485\n",
      "Epoch 624/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 316408.6250 - mae: 336.7250 - val_loss: 369900.2188 - val_mae: 361.0353\n",
      "Epoch 625/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 328441.8438 - mae: 330.4477 - val_loss: 373431.4375 - val_mae: 363.4791\n",
      "Epoch 626/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 335555.9375 - mae: 338.7981 - val_loss: 370518.6875 - val_mae: 361.5875\n",
      "Epoch 627/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 300838.0312 - mae: 324.1910 - val_loss: 368441.6562 - val_mae: 359.7489\n",
      "Epoch 628/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 341943.0312 - mae: 340.3185 - val_loss: 370527.1562 - val_mae: 361.4623\n",
      "Epoch 629/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 298228.2500 - mae: 324.4933 - val_loss: 374267.3750 - val_mae: 363.9517\n",
      "Epoch 630/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 328452.3750 - mae: 329.7735 - val_loss: 373173.9062 - val_mae: 363.3510\n",
      "Epoch 631/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 319971.6875 - mae: 334.5957 - val_loss: 370235.4688 - val_mae: 361.3356\n",
      "Epoch 632/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 297569.5625 - mae: 330.1497 - val_loss: 371894.8125 - val_mae: 362.8413\n",
      "Epoch 633/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 319952.5000 - mae: 329.1766 - val_loss: 368926.0000 - val_mae: 359.5573\n",
      "Epoch 634/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 314150.7500 - mae: 326.9544 - val_loss: 373737.5000 - val_mae: 363.8906\n",
      "Epoch 635/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 315578.6562 - mae: 328.1919 - val_loss: 369747.4375 - val_mae: 361.0114\n",
      "Epoch 636/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 346999.8125 - mae: 347.2868 - val_loss: 371974.5625 - val_mae: 362.1968\n",
      "Epoch 637/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 311345.5625 - mae: 331.3446 - val_loss: 375185.4688 - val_mae: 365.2423\n",
      "Epoch 638/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 301548.2812 - mae: 321.9606 - val_loss: 372380.0312 - val_mae: 362.9594\n",
      "Epoch 639/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 367232.6875 - mae: 346.9460 - val_loss: 371388.3125 - val_mae: 361.6553\n",
      "Epoch 640/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 339353.8125 - mae: 338.4464 - val_loss: 371676.9688 - val_mae: 362.4143\n",
      "Epoch 641/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 296315.8125 - mae: 313.1544 - val_loss: 372802.4688 - val_mae: 362.3007\n",
      "Epoch 642/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 303342.1250 - mae: 326.2999 - val_loss: 371335.5625 - val_mae: 361.6288\n",
      "Epoch 643/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 301792.5938 - mae: 323.7816 - val_loss: 370608.4688 - val_mae: 360.9048\n",
      "Epoch 644/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 343683.5312 - mae: 336.8761 - val_loss: 370370.9375 - val_mae: 360.4996\n",
      "Epoch 645/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 322884.0625 - mae: 326.3094 - val_loss: 370727.5625 - val_mae: 360.4445\n",
      "Epoch 646/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 330334.1875 - mae: 343.0705 - val_loss: 373875.5312 - val_mae: 364.4677\n",
      "Epoch 647/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 292810.7500 - mae: 314.6463 - val_loss: 371927.8750 - val_mae: 362.6633\n",
      "Epoch 648/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 325033.7188 - mae: 339.8253 - val_loss: 371424.8438 - val_mae: 361.2271\n",
      "Epoch 649/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 356694.2812 - mae: 352.1016 - val_loss: 370274.9062 - val_mae: 360.7929\n",
      "Epoch 650/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 331967.4688 - mae: 327.7705 - val_loss: 374428.0000 - val_mae: 364.2383\n",
      "Epoch 651/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 316334.1562 - mae: 328.6101 - val_loss: 373044.7188 - val_mae: 362.9259\n",
      "Epoch 652/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 275629.9375 - mae: 314.6991 - val_loss: 369449.0312 - val_mae: 360.0743\n",
      "Epoch 653/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 309805.0938 - mae: 324.0703 - val_loss: 371508.0312 - val_mae: 361.4314\n",
      "Epoch 654/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 309849.4062 - mae: 326.0050 - val_loss: 374477.7500 - val_mae: 363.7612\n",
      "Epoch 655/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 306241.5000 - mae: 327.0240 - val_loss: 370806.7500 - val_mae: 361.0932\n",
      "Epoch 656/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 279457.5625 - mae: 306.3535 - val_loss: 375281.1875 - val_mae: 364.7230\n",
      "Epoch 657/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 328560.7812 - mae: 340.6145 - val_loss: 372711.1562 - val_mae: 362.7089\n",
      "Epoch 658/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 351541.2500 - mae: 356.1003 - val_loss: 370625.2188 - val_mae: 361.1193\n",
      "Epoch 659/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 294883.6250 - mae: 316.1945 - val_loss: 372231.2188 - val_mae: 361.8098\n",
      "Epoch 660/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 267249.0938 - mae: 308.2274 - val_loss: 373924.4688 - val_mae: 364.4330\n",
      "Epoch 661/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 340388.0312 - mae: 346.4859 - val_loss: 373281.4062 - val_mae: 363.4562\n",
      "Epoch 662/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 303599.5000 - mae: 328.4735 - val_loss: 373127.9375 - val_mae: 362.4291\n",
      "Epoch 663/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 313941.6250 - mae: 329.0710 - val_loss: 372085.0000 - val_mae: 361.2939\n",
      "Epoch 664/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 269373.0625 - mae: 313.0376 - val_loss: 373462.8125 - val_mae: 362.6525\n",
      "Epoch 665/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 314958.0000 - mae: 333.0033 - val_loss: 373513.9062 - val_mae: 363.2834\n",
      "Epoch 666/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 293220.9062 - mae: 316.6176 - val_loss: 371131.6562 - val_mae: 361.1859\n",
      "Epoch 667/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 325655.0312 - mae: 324.0882 - val_loss: 373435.3125 - val_mae: 362.8251\n",
      "Epoch 668/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 310612.7812 - mae: 324.5735 - val_loss: 368418.2500 - val_mae: 359.5137\n",
      "Epoch 669/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 305104.3125 - mae: 327.5396 - val_loss: 372410.8750 - val_mae: 362.2620\n",
      "Epoch 670/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 300489.6562 - mae: 323.8898 - val_loss: 372920.9375 - val_mae: 363.3228\n",
      "Epoch 671/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 294584.4688 - mae: 325.3023 - val_loss: 378556.2812 - val_mae: 367.0430\n",
      "Epoch 672/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 341612.2812 - mae: 347.2447 - val_loss: 374102.2188 - val_mae: 363.5182\n",
      "Epoch 673/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 302047.0312 - mae: 328.6143 - val_loss: 375398.7188 - val_mae: 365.2996\n",
      "Epoch 674/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 317784.5312 - mae: 337.3293 - val_loss: 368844.6250 - val_mae: 358.7747\n",
      "Epoch 675/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 277938.8125 - mae: 311.0386 - val_loss: 372977.6562 - val_mae: 362.7332\n",
      "Epoch 676/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 332254.3125 - mae: 337.7249 - val_loss: 378247.0938 - val_mae: 367.3387\n",
      "Epoch 677/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 310557.6250 - mae: 333.0356 - val_loss: 370064.6875 - val_mae: 360.8105\n",
      "Epoch 678/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 310944.2812 - mae: 333.0693 - val_loss: 373719.9062 - val_mae: 362.2227\n",
      "Epoch 679/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 380854.4062 - mae: 354.7489 - val_loss: 373431.4062 - val_mae: 363.5486\n",
      "Epoch 680/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 303574.0938 - mae: 326.9622 - val_loss: 369952.8125 - val_mae: 360.2178\n",
      "Epoch 681/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 284529.6562 - mae: 310.8014 - val_loss: 372760.1562 - val_mae: 361.9629\n",
      "Epoch 682/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 305178.5938 - mae: 332.6633 - val_loss: 372648.8125 - val_mae: 362.4502\n",
      "Epoch 683/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 289223.0625 - mae: 315.6918 - val_loss: 371023.4062 - val_mae: 361.2493\n",
      "Epoch 684/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 340860.2188 - mae: 342.4822 - val_loss: 372705.2812 - val_mae: 362.5580\n",
      "Epoch 685/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 334609.1562 - mae: 340.8616 - val_loss: 369332.7188 - val_mae: 359.9989\n",
      "Epoch 686/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 348801.0312 - mae: 342.0568 - val_loss: 368300.0312 - val_mae: 358.7263\n",
      "Epoch 687/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 304757.9062 - mae: 326.6891 - val_loss: 370474.8125 - val_mae: 360.6647\n",
      "Epoch 688/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 361780.6875 - mae: 355.7055 - val_loss: 372225.8125 - val_mae: 362.5577\n",
      "Epoch 689/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 318999.6875 - mae: 327.6629 - val_loss: 368075.3125 - val_mae: 357.2570\n",
      "Epoch 690/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 369055.2812 - mae: 356.1504 - val_loss: 372020.7500 - val_mae: 362.8328\n",
      "Epoch 691/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 327049.8125 - mae: 327.9477 - val_loss: 370104.5312 - val_mae: 360.4723\n",
      "Epoch 692/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 331187.3750 - mae: 344.7216 - val_loss: 374277.3750 - val_mae: 364.0274\n",
      "Epoch 693/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 304898.0938 - mae: 339.6449 - val_loss: 371839.5938 - val_mae: 361.4728\n",
      "Epoch 694/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 316759.8125 - mae: 327.8954 - val_loss: 373741.3125 - val_mae: 362.6171\n",
      "Epoch 695/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 319609.7812 - mae: 332.6803 - val_loss: 372662.9375 - val_mae: 362.2175\n",
      "Epoch 696/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 318936.1250 - mae: 329.0790 - val_loss: 371676.5000 - val_mae: 360.9069\n",
      "Epoch 697/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 368370.0625 - mae: 340.8754 - val_loss: 367906.1562 - val_mae: 357.1668\n",
      "Epoch 698/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 313014.9375 - mae: 329.3946 - val_loss: 372068.4688 - val_mae: 361.8559\n",
      "Epoch 699/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 334009.5312 - mae: 343.2977 - val_loss: 372401.0312 - val_mae: 362.3949\n",
      "Epoch 700/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 315470.8438 - mae: 332.3313 - val_loss: 371092.6250 - val_mae: 360.7591\n",
      "Epoch 701/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 315794.9688 - mae: 331.2878 - val_loss: 372110.1250 - val_mae: 361.6753\n",
      "Epoch 702/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 291705.8125 - mae: 317.7053 - val_loss: 369022.0000 - val_mae: 358.4045\n",
      "Epoch 703/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 395209.3125 - mae: 365.0398 - val_loss: 370954.7812 - val_mae: 360.3799\n",
      "Epoch 704/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 290538.1250 - mae: 320.2752 - val_loss: 375493.4062 - val_mae: 365.1213\n",
      "Epoch 705/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 304587.0000 - mae: 333.8548 - val_loss: 370118.1562 - val_mae: 361.0901\n",
      "Epoch 706/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 307883.0938 - mae: 321.3994 - val_loss: 372564.3750 - val_mae: 362.4139\n",
      "Epoch 707/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 303209.1250 - mae: 331.8051 - val_loss: 372873.9375 - val_mae: 361.5869\n",
      "Epoch 708/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 331677.0938 - mae: 332.2896 - val_loss: 373411.6875 - val_mae: 362.5149\n",
      "Epoch 709/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 341917.9688 - mae: 344.2962 - val_loss: 369448.5312 - val_mae: 358.3353\n",
      "Epoch 710/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 320351.6250 - mae: 328.2633 - val_loss: 371310.8125 - val_mae: 361.2454\n",
      "Epoch 711/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 315909.9688 - mae: 320.1837 - val_loss: 372021.9375 - val_mae: 362.3754\n",
      "Epoch 712/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 328941.6875 - mae: 334.4634 - val_loss: 371934.7188 - val_mae: 361.4786\n",
      "Epoch 713/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 298641.4375 - mae: 321.0664 - val_loss: 372183.9688 - val_mae: 361.8411\n",
      "Epoch 714/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 350158.1250 - mae: 346.8848 - val_loss: 370146.1250 - val_mae: 360.2466\n",
      "Epoch 715/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 287083.9375 - mae: 318.4922 - val_loss: 369861.2188 - val_mae: 360.4391\n",
      "Epoch 716/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 293103.6875 - mae: 311.4422 - val_loss: 370890.0625 - val_mae: 360.5345\n",
      "Epoch 717/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 355423.0000 - mae: 347.8845 - val_loss: 369999.3438 - val_mae: 359.4778\n",
      "Epoch 718/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 324312.9375 - mae: 338.8861 - val_loss: 369156.0312 - val_mae: 358.9045\n",
      "Epoch 719/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 288833.7812 - mae: 317.5946 - val_loss: 374465.0625 - val_mae: 363.5822\n",
      "Epoch 720/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 287335.1250 - mae: 319.2795 - val_loss: 374071.3438 - val_mae: 363.7152\n",
      "Epoch 721/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 307503.2188 - mae: 323.7019 - val_loss: 370662.2500 - val_mae: 360.1452\n",
      "Epoch 722/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 317969.5000 - mae: 330.6689 - val_loss: 374491.5938 - val_mae: 364.5540\n",
      "Epoch 723/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 370907.2188 - mae: 346.5995 - val_loss: 372367.6562 - val_mae: 361.7932\n",
      "Epoch 724/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 260466.0312 - mae: 302.3025 - val_loss: 369738.2500 - val_mae: 359.3439\n",
      "Epoch 725/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 317125.6250 - mae: 329.4071 - val_loss: 371281.4688 - val_mae: 361.1301\n",
      "Epoch 726/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 317202.6562 - mae: 339.4252 - val_loss: 370189.5000 - val_mae: 359.8483\n",
      "Epoch 727/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 304624.0312 - mae: 334.1576 - val_loss: 374903.3750 - val_mae: 364.1926\n",
      "Epoch 728/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 390839.0000 - mae: 358.2776 - val_loss: 372022.7188 - val_mae: 361.5664\n",
      "Epoch 729/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 275542.3125 - mae: 311.8425 - val_loss: 372270.8438 - val_mae: 361.6047\n",
      "Epoch 730/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 311564.0312 - mae: 328.4494 - val_loss: 371347.8438 - val_mae: 361.1353\n",
      "Epoch 731/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 316842.4062 - mae: 327.0751 - val_loss: 372297.5312 - val_mae: 361.2764\n",
      "Epoch 732/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 275148.9688 - mae: 310.3008 - val_loss: 372664.1562 - val_mae: 361.6352\n",
      "Epoch 733/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 342203.5000 - mae: 338.0632 - val_loss: 372482.3750 - val_mae: 361.6346\n",
      "Epoch 734/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 293699.6562 - mae: 317.6764 - val_loss: 372397.5938 - val_mae: 361.7682\n",
      "Epoch 735/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 314891.6250 - mae: 332.0896 - val_loss: 370422.1250 - val_mae: 360.8949\n",
      "Epoch 736/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 336376.7812 - mae: 341.4413 - val_loss: 371076.4375 - val_mae: 359.8325\n",
      "Epoch 737/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 305818.1250 - mae: 333.9753 - val_loss: 372740.7812 - val_mae: 362.1860\n",
      "Epoch 738/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 293645.7188 - mae: 323.3321 - val_loss: 370409.6562 - val_mae: 360.1656\n",
      "Epoch 739/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 303750.8438 - mae: 325.9024 - val_loss: 372959.9375 - val_mae: 362.7707\n",
      "Epoch 740/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 324491.9062 - mae: 329.5295 - val_loss: 371802.9375 - val_mae: 360.8697\n",
      "Epoch 741/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 301558.1562 - mae: 316.3806 - val_loss: 371260.9062 - val_mae: 360.4227\n",
      "Epoch 742/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 276806.6250 - mae: 317.6511 - val_loss: 371360.7812 - val_mae: 360.6183\n",
      "Epoch 743/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 361422.1562 - mae: 346.0969 - val_loss: 373256.8750 - val_mae: 362.3434\n",
      "Epoch 744/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 285456.7500 - mae: 316.4458 - val_loss: 373228.4688 - val_mae: 361.7038\n",
      "Epoch 745/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 330885.6875 - mae: 337.8176 - val_loss: 373603.2188 - val_mae: 363.8400\n",
      "Epoch 746/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 337220.5938 - mae: 344.1425 - val_loss: 370423.3438 - val_mae: 360.8457\n",
      "Epoch 747/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 328402.4688 - mae: 334.5967 - val_loss: 372792.9688 - val_mae: 362.4637\n",
      "Epoch 748/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 291977.8750 - mae: 317.8748 - val_loss: 370722.6250 - val_mae: 361.6007\n",
      "Epoch 749/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 339450.1250 - mae: 339.8959 - val_loss: 373042.5000 - val_mae: 362.9042\n",
      "Epoch 750/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 283727.3125 - mae: 320.2121 - val_loss: 372941.8750 - val_mae: 362.3305\n",
      "Epoch 751/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 315485.6250 - mae: 332.3039 - val_loss: 374065.8125 - val_mae: 363.2827\n",
      "Epoch 752/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318695.4375 - mae: 327.9803 - val_loss: 371504.5938 - val_mae: 361.5480\n",
      "Epoch 753/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 364548.0000 - mae: 347.2092 - val_loss: 370910.0312 - val_mae: 360.8890\n",
      "Epoch 754/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 330771.7500 - mae: 337.6786 - val_loss: 373964.9688 - val_mae: 362.6274\n",
      "Epoch 755/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 347780.5312 - mae: 339.2817 - val_loss: 372069.0938 - val_mae: 361.1330\n",
      "Epoch 756/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 321735.3438 - mae: 331.8789 - val_loss: 372862.4375 - val_mae: 361.7048\n",
      "Epoch 757/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 355608.5000 - mae: 352.8145 - val_loss: 370515.2812 - val_mae: 358.7652\n",
      "Epoch 758/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 276669.5938 - mae: 310.7401 - val_loss: 372518.4062 - val_mae: 362.1618\n",
      "Epoch 759/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 313701.0938 - mae: 328.6234 - val_loss: 370746.9062 - val_mae: 359.6456\n",
      "Epoch 760/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 289608.0000 - mae: 313.6970 - val_loss: 370963.1562 - val_mae: 359.6620\n",
      "Epoch 761/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 303143.7188 - mae: 319.7655 - val_loss: 370958.7812 - val_mae: 360.9138\n",
      "Epoch 762/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 354382.4062 - mae: 337.3049 - val_loss: 371476.0312 - val_mae: 361.0333\n",
      "Epoch 763/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 276128.0000 - mae: 309.0470 - val_loss: 370364.0625 - val_mae: 360.4360\n",
      "Epoch 764/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 376455.1250 - mae: 343.0812 - val_loss: 370045.3750 - val_mae: 359.8561\n",
      "Epoch 765/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 357130.5938 - mae: 343.9050 - val_loss: 370492.7812 - val_mae: 360.4270\n",
      "Epoch 766/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 326783.4062 - mae: 332.7879 - val_loss: 371399.0312 - val_mae: 360.8145\n",
      "Epoch 767/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 317341.1875 - mae: 330.1009 - val_loss: 371551.8438 - val_mae: 361.3951\n",
      "Epoch 768/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 295345.2188 - mae: 320.8553 - val_loss: 372494.3438 - val_mae: 362.5719\n",
      "Epoch 769/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 282471.1250 - mae: 318.2568 - val_loss: 370747.3750 - val_mae: 361.0215\n",
      "Epoch 770/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 341859.0625 - mae: 340.5114 - val_loss: 370235.7812 - val_mae: 359.4337\n",
      "Epoch 771/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 313343.9375 - mae: 327.8986 - val_loss: 372230.0625 - val_mae: 361.9089\n",
      "Epoch 772/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 294979.0938 - mae: 323.3705 - val_loss: 370327.0625 - val_mae: 360.3130\n",
      "Epoch 773/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 352953.1250 - mae: 346.9356 - val_loss: 373181.7812 - val_mae: 362.5944\n",
      "Epoch 774/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331245.0000 - mae: 333.7260 - val_loss: 372958.0000 - val_mae: 362.4107\n",
      "Epoch 775/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 292923.9062 - mae: 329.1635 - val_loss: 369938.6250 - val_mae: 360.1343\n",
      "Epoch 776/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 270796.3750 - mae: 314.9234 - val_loss: 377064.3125 - val_mae: 365.8990\n",
      "Epoch 777/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 295115.3750 - mae: 325.8920 - val_loss: 370410.5312 - val_mae: 359.9535\n",
      "Epoch 778/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 327792.7500 - mae: 333.2816 - val_loss: 372090.5000 - val_mae: 361.7422\n",
      "Epoch 779/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 345441.1875 - mae: 337.7041 - val_loss: 368455.2812 - val_mae: 358.3719\n",
      "Epoch 780/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 277845.1250 - mae: 315.4803 - val_loss: 370864.5625 - val_mae: 360.6224\n",
      "Epoch 781/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 301085.2812 - mae: 325.1000 - val_loss: 370759.0938 - val_mae: 361.0111\n",
      "Epoch 782/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 329065.3750 - mae: 336.0208 - val_loss: 370281.1562 - val_mae: 360.2478\n",
      "Epoch 783/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 290210.9375 - mae: 313.9287 - val_loss: 372375.0938 - val_mae: 361.7930\n",
      "Epoch 784/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 301567.3750 - mae: 319.7849 - val_loss: 371532.6562 - val_mae: 361.6925\n",
      "Epoch 785/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 375432.5938 - mae: 358.0532 - val_loss: 370282.8438 - val_mae: 359.7781\n",
      "Epoch 786/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 279663.7500 - mae: 325.3652 - val_loss: 374169.4062 - val_mae: 363.8052\n",
      "Epoch 787/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 338446.5312 - mae: 338.7722 - val_loss: 372492.4688 - val_mae: 361.7173\n",
      "Epoch 788/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 275911.6875 - mae: 314.5153 - val_loss: 370299.2812 - val_mae: 361.1148\n",
      "Epoch 789/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 297661.5938 - mae: 330.3026 - val_loss: 372748.1250 - val_mae: 362.2179\n",
      "Epoch 790/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 316084.2500 - mae: 329.4118 - val_loss: 372752.7812 - val_mae: 362.9855\n",
      "Epoch 791/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 320395.5938 - mae: 333.9207 - val_loss: 370276.8438 - val_mae: 359.6486\n",
      "Epoch 792/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 296773.2500 - mae: 325.8154 - val_loss: 375000.1875 - val_mae: 364.2595\n",
      "Epoch 793/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 354126.0625 - mae: 352.0515 - val_loss: 370071.0938 - val_mae: 359.9081\n",
      "Epoch 794/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 302503.7500 - mae: 324.6995 - val_loss: 371850.9062 - val_mae: 361.0272\n",
      "Epoch 795/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 302045.4062 - mae: 318.2157 - val_loss: 374990.8125 - val_mae: 363.5829\n",
      "Epoch 796/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 309771.0938 - mae: 324.9700 - val_loss: 368237.0000 - val_mae: 357.5943\n",
      "Epoch 797/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 296175.6875 - mae: 323.2443 - val_loss: 372446.3125 - val_mae: 361.6369\n",
      "Epoch 798/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 325226.8438 - mae: 334.3560 - val_loss: 372325.0625 - val_mae: 361.6990\n",
      "Epoch 799/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 295873.5312 - mae: 321.3521 - val_loss: 370532.2500 - val_mae: 360.1274\n",
      "Epoch 800/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 350277.6250 - mae: 335.8463 - val_loss: 373129.8125 - val_mae: 362.5675\n",
      "Epoch 801/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335938.7812 - mae: 337.6378 - val_loss: 371212.5625 - val_mae: 359.4991\n",
      "Epoch 802/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 336080.2188 - mae: 337.3656 - val_loss: 370300.8750 - val_mae: 359.5827\n",
      "Epoch 803/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 307912.1562 - mae: 324.5385 - val_loss: 374131.6562 - val_mae: 363.1653\n",
      "Epoch 804/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 287701.6562 - mae: 310.5473 - val_loss: 369401.5625 - val_mae: 358.6594\n",
      "Epoch 805/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 317899.5312 - mae: 328.6258 - val_loss: 370318.4688 - val_mae: 360.1773\n",
      "Epoch 806/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 352434.4062 - mae: 339.2535 - val_loss: 369707.7812 - val_mae: 358.8757\n",
      "Epoch 807/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 280290.0938 - mae: 307.2360 - val_loss: 372278.6562 - val_mae: 361.3029\n",
      "Epoch 808/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 294801.2188 - mae: 318.1356 - val_loss: 371495.2812 - val_mae: 361.2512\n",
      "Epoch 809/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 341645.6250 - mae: 340.9409 - val_loss: 375526.0000 - val_mae: 364.2021\n",
      "Epoch 810/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 361363.3750 - mae: 348.3517 - val_loss: 371455.3125 - val_mae: 360.2688\n",
      "Epoch 811/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 281259.8750 - mae: 318.5388 - val_loss: 374762.5625 - val_mae: 363.3929\n",
      "Epoch 812/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 310533.4375 - mae: 324.1077 - val_loss: 375802.8438 - val_mae: 364.2791\n",
      "Epoch 813/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 303626.6250 - mae: 330.7469 - val_loss: 371734.0625 - val_mae: 361.1978\n",
      "Epoch 814/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 287670.8125 - mae: 311.2000 - val_loss: 373109.6875 - val_mae: 361.2967\n",
      "Epoch 815/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 291331.5312 - mae: 321.2635 - val_loss: 372299.1562 - val_mae: 361.1351\n",
      "Epoch 816/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 320516.0625 - mae: 331.1525 - val_loss: 372803.7188 - val_mae: 361.5398\n",
      "Epoch 817/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 301302.6562 - mae: 321.9926 - val_loss: 376288.5938 - val_mae: 365.0815\n",
      "Epoch 818/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 302006.6562 - mae: 324.7944 - val_loss: 373089.9062 - val_mae: 362.3627\n",
      "Epoch 819/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 269961.6562 - mae: 310.1153 - val_loss: 372355.2812 - val_mae: 361.8647\n",
      "Epoch 820/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 302690.1875 - mae: 327.7435 - val_loss: 370854.7500 - val_mae: 360.0750\n",
      "Epoch 821/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 343741.6875 - mae: 340.9782 - val_loss: 370566.2500 - val_mae: 359.8516\n",
      "Epoch 822/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 330233.8750 - mae: 338.4532 - val_loss: 369267.7188 - val_mae: 358.6750\n",
      "Epoch 823/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 329369.7188 - mae: 326.7936 - val_loss: 371488.5625 - val_mae: 359.2394\n",
      "Epoch 824/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331063.7188 - mae: 335.3828 - val_loss: 372277.5938 - val_mae: 361.1634\n",
      "Epoch 825/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 250046.5781 - mae: 302.0584 - val_loss: 373747.2500 - val_mae: 362.8594\n",
      "Epoch 826/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 288426.5938 - mae: 317.0480 - val_loss: 370564.0312 - val_mae: 359.0207\n",
      "Epoch 827/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 301341.8125 - mae: 320.4392 - val_loss: 371444.4062 - val_mae: 360.4933\n",
      "Epoch 828/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 322428.8750 - mae: 329.5957 - val_loss: 372808.3125 - val_mae: 362.7961\n",
      "Epoch 829/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 294817.5312 - mae: 324.5493 - val_loss: 372391.5938 - val_mae: 362.5633\n",
      "Epoch 830/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 313315.5312 - mae: 325.9497 - val_loss: 371480.2188 - val_mae: 360.9791\n",
      "Epoch 831/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 288397.7812 - mae: 315.3344 - val_loss: 370426.6250 - val_mae: 361.4490\n",
      "Epoch 832/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 281124.4062 - mae: 319.4038 - val_loss: 371328.4375 - val_mae: 360.1357\n",
      "Epoch 833/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 292266.6875 - mae: 315.0727 - val_loss: 372127.6875 - val_mae: 361.7014\n",
      "Epoch 834/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 293433.8438 - mae: 325.1118 - val_loss: 378178.2500 - val_mae: 367.3711\n",
      "Epoch 835/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 295146.6562 - mae: 321.9646 - val_loss: 371651.9062 - val_mae: 360.0684\n",
      "Epoch 836/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 336960.4375 - mae: 337.2467 - val_loss: 372563.4375 - val_mae: 361.0441\n",
      "Epoch 837/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 312251.4688 - mae: 329.5840 - val_loss: 372086.3750 - val_mae: 360.6714\n",
      "Epoch 838/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 282464.7188 - mae: 322.0168 - val_loss: 372899.6562 - val_mae: 361.4738\n",
      "Epoch 839/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 328805.8750 - mae: 339.1218 - val_loss: 372606.3438 - val_mae: 362.4180\n",
      "Epoch 840/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 349782.7812 - mae: 347.9933 - val_loss: 375091.7812 - val_mae: 363.5956\n",
      "Epoch 841/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 317405.2500 - mae: 323.3336 - val_loss: 371815.8750 - val_mae: 361.2984\n",
      "Epoch 842/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 321971.0938 - mae: 335.7190 - val_loss: 370818.3750 - val_mae: 360.5990\n",
      "Epoch 843/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 344675.5938 - mae: 344.9537 - val_loss: 370734.0625 - val_mae: 360.7868\n",
      "Epoch 844/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 297098.1250 - mae: 321.9838 - val_loss: 372550.6875 - val_mae: 361.1941\n",
      "Epoch 845/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 293335.3125 - mae: 322.7633 - val_loss: 374285.6250 - val_mae: 362.0757\n",
      "Epoch 846/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331254.9688 - mae: 333.4687 - val_loss: 372279.1875 - val_mae: 361.9596\n",
      "Epoch 847/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 286106.0938 - mae: 320.2589 - val_loss: 371565.7500 - val_mae: 359.5466\n",
      "Epoch 848/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 274170.2188 - mae: 308.5283 - val_loss: 371394.8750 - val_mae: 360.9500\n",
      "Epoch 849/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 300726.4375 - mae: 322.8045 - val_loss: 372685.5938 - val_mae: 361.6649\n",
      "Epoch 850/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 303785.7812 - mae: 327.2945 - val_loss: 370464.7188 - val_mae: 359.6902\n",
      "Epoch 851/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 284147.3750 - mae: 316.0640 - val_loss: 375739.1250 - val_mae: 364.8828\n",
      "Epoch 852/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 331385.4688 - mae: 338.8851 - val_loss: 371650.5312 - val_mae: 360.5296\n",
      "Epoch 853/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 307809.5938 - mae: 319.0144 - val_loss: 372513.0000 - val_mae: 361.8971\n",
      "Epoch 854/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 340331.0312 - mae: 347.4118 - val_loss: 372216.3125 - val_mae: 360.7523\n",
      "Epoch 855/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 307187.7812 - mae: 331.5217 - val_loss: 371301.3750 - val_mae: 360.7072\n",
      "Epoch 856/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 284465.8438 - mae: 316.0058 - val_loss: 369981.3438 - val_mae: 359.7608\n",
      "Epoch 857/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 356477.5938 - mae: 342.6023 - val_loss: 373131.3750 - val_mae: 362.5661\n",
      "Epoch 858/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 287386.9375 - mae: 321.8963 - val_loss: 370881.2812 - val_mae: 359.9573\n",
      "Epoch 859/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 256421.1562 - mae: 301.5906 - val_loss: 375423.0312 - val_mae: 363.8148\n",
      "Epoch 860/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 286345.5312 - mae: 313.0349 - val_loss: 371178.3438 - val_mae: 359.7909\n",
      "Epoch 861/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 277906.2812 - mae: 314.8268 - val_loss: 369662.2188 - val_mae: 357.8151\n",
      "Epoch 862/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 288621.5000 - mae: 319.7300 - val_loss: 372657.6562 - val_mae: 361.1273\n",
      "Epoch 863/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 318353.7812 - mae: 330.1534 - val_loss: 371394.0625 - val_mae: 360.7739\n",
      "Epoch 864/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 372833.5312 - mae: 346.4331 - val_loss: 371677.8750 - val_mae: 361.5298\n",
      "Epoch 865/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 293724.0625 - mae: 319.3790 - val_loss: 371842.1875 - val_mae: 361.4843\n",
      "Epoch 866/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 305505.7500 - mae: 330.8835 - val_loss: 371408.2188 - val_mae: 361.0709\n",
      "Epoch 867/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 272382.3125 - mae: 310.2085 - val_loss: 372979.7500 - val_mae: 361.5525\n",
      "Epoch 868/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 287361.2188 - mae: 317.6367 - val_loss: 370117.9062 - val_mae: 359.9576\n",
      "Epoch 869/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 303259.8438 - mae: 327.8084 - val_loss: 369880.9688 - val_mae: 358.6633\n",
      "Epoch 870/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 334169.8750 - mae: 332.4536 - val_loss: 373135.1562 - val_mae: 361.1800\n",
      "Epoch 871/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 336454.2500 - mae: 331.0423 - val_loss: 371055.0312 - val_mae: 360.4877\n",
      "Epoch 872/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 327605.5938 - mae: 335.8399 - val_loss: 374016.2188 - val_mae: 363.4541\n",
      "Epoch 873/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 304327.2188 - mae: 326.8271 - val_loss: 374132.0312 - val_mae: 363.4464\n",
      "Epoch 874/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 300306.8125 - mae: 320.5123 - val_loss: 374670.3125 - val_mae: 363.9057\n",
      "Epoch 875/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 329645.6875 - mae: 335.3290 - val_loss: 371577.1875 - val_mae: 361.2148\n",
      "Epoch 876/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 269503.1875 - mae: 314.4848 - val_loss: 375581.9688 - val_mae: 363.3529\n",
      "Epoch 877/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 266016.8125 - mae: 306.8445 - val_loss: 369208.5938 - val_mae: 359.0876\n",
      "Epoch 878/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 293940.0312 - mae: 319.7935 - val_loss: 371714.6875 - val_mae: 360.8308\n",
      "Epoch 879/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 330656.2188 - mae: 333.5199 - val_loss: 370272.5625 - val_mae: 359.6212\n",
      "Epoch 880/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 284245.8438 - mae: 307.6668 - val_loss: 375717.6875 - val_mae: 364.5295\n",
      "Epoch 881/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 299103.8125 - mae: 317.6416 - val_loss: 371826.6250 - val_mae: 360.6368\n",
      "Epoch 882/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 331505.3125 - mae: 327.5421 - val_loss: 374158.8125 - val_mae: 363.4298\n",
      "Epoch 883/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 318825.8125 - mae: 330.8876 - val_loss: 371550.5625 - val_mae: 361.2753\n",
      "Epoch 884/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 304429.0625 - mae: 322.0859 - val_loss: 372480.6875 - val_mae: 361.6753\n",
      "Epoch 885/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 297440.2188 - mae: 320.6226 - val_loss: 373062.4688 - val_mae: 362.1227\n",
      "Epoch 886/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 297249.3750 - mae: 319.1769 - val_loss: 373959.2188 - val_mae: 363.0868\n",
      "Epoch 887/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 283933.5312 - mae: 310.2723 - val_loss: 373312.9062 - val_mae: 363.3891\n",
      "Epoch 888/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 310951.5938 - mae: 324.0222 - val_loss: 373925.5938 - val_mae: 362.8110\n",
      "Epoch 889/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 315506.2812 - mae: 334.1092 - val_loss: 371668.6875 - val_mae: 360.7334\n",
      "Epoch 890/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 297545.2188 - mae: 317.3499 - val_loss: 376514.4375 - val_mae: 364.8169\n",
      "Epoch 891/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 307499.0000 - mae: 332.0611 - val_loss: 369778.2500 - val_mae: 358.8109\n",
      "Epoch 892/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 290618.5938 - mae: 320.6654 - val_loss: 372911.5625 - val_mae: 362.9503\n",
      "Epoch 893/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 312358.7500 - mae: 326.7089 - val_loss: 372249.9375 - val_mae: 360.3515\n",
      "Epoch 894/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 313759.6875 - mae: 329.8143 - val_loss: 373677.4688 - val_mae: 363.0262\n",
      "Epoch 895/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 383646.6562 - mae: 359.5078 - val_loss: 371931.6250 - val_mae: 361.5436\n",
      "Epoch 896/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 302904.8750 - mae: 326.8565 - val_loss: 372972.9688 - val_mae: 361.4952\n",
      "Epoch 897/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 312728.6875 - mae: 315.7756 - val_loss: 373620.2500 - val_mae: 361.9991\n",
      "Epoch 898/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 324698.1875 - mae: 336.1971 - val_loss: 369991.9062 - val_mae: 358.7768\n",
      "Epoch 899/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 302496.0625 - mae: 315.6521 - val_loss: 371978.1250 - val_mae: 362.1885\n",
      "Epoch 900/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 306246.3750 - mae: 325.2739 - val_loss: 371022.6250 - val_mae: 360.4685\n",
      "Epoch 901/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 328952.8750 - mae: 334.7497 - val_loss: 371417.8125 - val_mae: 360.5518\n",
      "Epoch 902/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 285508.2812 - mae: 312.7188 - val_loss: 371756.4062 - val_mae: 361.4297\n",
      "Epoch 903/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 287958.6250 - mae: 315.1764 - val_loss: 368848.9688 - val_mae: 358.4300\n",
      "Epoch 904/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 280943.2500 - mae: 309.7617 - val_loss: 371921.7812 - val_mae: 361.2432\n",
      "Epoch 905/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 294280.5000 - mae: 320.2027 - val_loss: 373409.9062 - val_mae: 362.7885\n",
      "Epoch 906/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 321617.5938 - mae: 325.0964 - val_loss: 371099.8125 - val_mae: 359.7961\n",
      "Epoch 907/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 249451.5000 - mae: 296.9458 - val_loss: 372317.5000 - val_mae: 360.5128\n",
      "Epoch 908/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 262757.0625 - mae: 304.5360 - val_loss: 373074.4062 - val_mae: 362.4071\n",
      "Epoch 909/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 303163.6875 - mae: 324.6968 - val_loss: 370996.9062 - val_mae: 359.8275\n",
      "Epoch 910/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 322087.7500 - mae: 337.3163 - val_loss: 369238.8125 - val_mae: 359.6855\n",
      "Epoch 911/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 268684.0938 - mae: 311.8109 - val_loss: 372088.8750 - val_mae: 360.8824\n",
      "Epoch 912/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 307823.0938 - mae: 320.3032 - val_loss: 368915.6875 - val_mae: 359.2638\n",
      "Epoch 913/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 290081.6875 - mae: 318.9809 - val_loss: 377026.1250 - val_mae: 366.3736\n",
      "Epoch 914/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 281868.9062 - mae: 317.5371 - val_loss: 374454.0000 - val_mae: 363.5367\n",
      "Epoch 915/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 305552.5000 - mae: 324.1392 - val_loss: 370950.5938 - val_mae: 360.7325\n",
      "Epoch 916/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 317005.7188 - mae: 327.4334 - val_loss: 372674.3125 - val_mae: 361.0797\n",
      "Epoch 917/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 333430.5312 - mae: 336.7683 - val_loss: 371195.3750 - val_mae: 357.9646\n",
      "Epoch 918/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 326786.2188 - mae: 330.7823 - val_loss: 372776.1562 - val_mae: 362.6672\n",
      "Epoch 919/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 350275.8750 - mae: 333.3377 - val_loss: 371586.3750 - val_mae: 361.2068\n",
      "Epoch 920/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 284668.4062 - mae: 311.0776 - val_loss: 370901.0625 - val_mae: 361.0613\n",
      "Epoch 921/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 314357.8750 - mae: 327.0540 - val_loss: 373344.0312 - val_mae: 363.1024\n",
      "Epoch 922/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 278854.0000 - mae: 314.6246 - val_loss: 372644.8438 - val_mae: 362.2419\n",
      "Epoch 923/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 374840.6250 - mae: 345.4415 - val_loss: 372237.9375 - val_mae: 360.2171\n",
      "Epoch 924/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 262960.5000 - mae: 309.2834 - val_loss: 371634.8750 - val_mae: 361.0232\n",
      "Epoch 925/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 325609.1875 - mae: 338.1979 - val_loss: 370574.7188 - val_mae: 360.2012\n",
      "Epoch 926/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 316217.7812 - mae: 327.4905 - val_loss: 373020.9688 - val_mae: 361.3882\n",
      "Epoch 927/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 298139.5312 - mae: 316.3402 - val_loss: 376283.0000 - val_mae: 365.1711\n",
      "Epoch 928/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 293327.0312 - mae: 322.0755 - val_loss: 370876.5625 - val_mae: 359.5370\n",
      "Epoch 929/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 337047.0312 - mae: 332.2095 - val_loss: 371272.6875 - val_mae: 360.3652\n",
      "Epoch 930/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 334448.7188 - mae: 342.1501 - val_loss: 371897.6562 - val_mae: 361.5630\n",
      "Epoch 931/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 298540.7812 - mae: 325.5757 - val_loss: 373908.4062 - val_mae: 363.0249\n",
      "Epoch 932/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 284284.6562 - mae: 323.8127 - val_loss: 371943.1875 - val_mae: 361.0039\n",
      "Epoch 933/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 293466.6562 - mae: 328.7597 - val_loss: 373217.6250 - val_mae: 361.4401\n",
      "Epoch 934/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 308340.6562 - mae: 329.9594 - val_loss: 371878.9375 - val_mae: 361.2347\n",
      "Epoch 935/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 325360.9062 - mae: 324.8069 - val_loss: 372377.8438 - val_mae: 361.6678\n",
      "Epoch 936/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 310689.0000 - mae: 326.0298 - val_loss: 372175.0625 - val_mae: 361.2576\n",
      "Epoch 937/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 294199.3750 - mae: 320.6251 - val_loss: 376667.8438 - val_mae: 365.7944\n",
      "Epoch 938/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 315397.0938 - mae: 320.1378 - val_loss: 371208.2188 - val_mae: 360.6051\n",
      "Epoch 939/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 307888.7500 - mae: 330.9208 - val_loss: 371087.4688 - val_mae: 360.4845\n",
      "Epoch 940/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 285922.9062 - mae: 313.9031 - val_loss: 370897.5000 - val_mae: 359.9078\n",
      "Epoch 941/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 316209.9062 - mae: 329.8685 - val_loss: 371747.2188 - val_mae: 360.5804\n",
      "Epoch 942/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 290340.6875 - mae: 326.7595 - val_loss: 373901.1250 - val_mae: 362.3406\n",
      "Epoch 943/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 295538.3125 - mae: 321.9374 - val_loss: 372949.2188 - val_mae: 361.9797\n",
      "Epoch 944/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 290114.7188 - mae: 316.1808 - val_loss: 369950.1875 - val_mae: 359.7398\n",
      "Epoch 945/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 319351.1875 - mae: 329.1279 - val_loss: 369596.7500 - val_mae: 358.9403\n",
      "Epoch 946/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 311855.9062 - mae: 331.5231 - val_loss: 372014.0625 - val_mae: 361.2879\n",
      "Epoch 947/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 336267.7500 - mae: 339.7294 - val_loss: 370858.8125 - val_mae: 359.2929\n",
      "Epoch 948/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 285155.4062 - mae: 313.6009 - val_loss: 371733.2188 - val_mae: 360.9372\n",
      "Epoch 949/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 286092.2500 - mae: 314.4865 - val_loss: 373255.9688 - val_mae: 361.9922\n",
      "Epoch 950/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318971.8438 - mae: 331.1593 - val_loss: 369375.0625 - val_mae: 358.6768\n",
      "Epoch 951/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 331848.9375 - mae: 339.1016 - val_loss: 374014.4375 - val_mae: 363.3013\n",
      "Epoch 952/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 279918.5312 - mae: 302.5886 - val_loss: 372143.6562 - val_mae: 359.9417\n",
      "Epoch 953/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 319136.2188 - mae: 335.9097 - val_loss: 371319.6875 - val_mae: 359.7440\n",
      "Epoch 954/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 304165.7500 - mae: 332.5072 - val_loss: 373264.5000 - val_mae: 362.7867\n",
      "Epoch 955/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 338923.5000 - mae: 336.0679 - val_loss: 370300.7812 - val_mae: 358.5348\n",
      "Epoch 956/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 301901.2188 - mae: 324.9326 - val_loss: 371440.0000 - val_mae: 361.0668\n",
      "Epoch 957/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 308560.0000 - mae: 326.1941 - val_loss: 368646.6250 - val_mae: 358.1282\n",
      "Epoch 958/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 327504.8125 - mae: 330.7559 - val_loss: 372527.4688 - val_mae: 361.6584\n",
      "Epoch 959/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 313778.6562 - mae: 326.9342 - val_loss: 371193.0938 - val_mae: 360.5206\n",
      "Epoch 960/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 290750.1562 - mae: 313.9520 - val_loss: 373106.6562 - val_mae: 363.3365\n",
      "Epoch 961/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 315497.2500 - mae: 328.6796 - val_loss: 370012.8125 - val_mae: 359.4236\n",
      "Epoch 962/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 296962.5000 - mae: 317.8070 - val_loss: 370553.9062 - val_mae: 359.4893\n",
      "Epoch 963/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 325719.7188 - mae: 331.8450 - val_loss: 369839.0000 - val_mae: 360.0393\n",
      "Epoch 964/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 326372.0625 - mae: 328.3002 - val_loss: 374741.4375 - val_mae: 364.7587\n",
      "Epoch 965/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 303642.0312 - mae: 320.7021 - val_loss: 370563.6875 - val_mae: 360.0103\n",
      "Epoch 966/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 297642.3125 - mae: 311.2868 - val_loss: 374188.4688 - val_mae: 362.1781\n",
      "Epoch 967/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 344325.8438 - mae: 341.7163 - val_loss: 376202.8438 - val_mae: 366.1395\n",
      "Epoch 968/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 320661.0625 - mae: 330.1433 - val_loss: 372255.3438 - val_mae: 361.8503\n",
      "Epoch 969/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 284232.8125 - mae: 320.6901 - val_loss: 372214.5000 - val_mae: 360.9175\n",
      "Epoch 970/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 321671.6875 - mae: 337.3346 - val_loss: 370156.5625 - val_mae: 359.5956\n",
      "Epoch 971/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 289776.5000 - mae: 319.1661 - val_loss: 375570.0312 - val_mae: 364.3929\n",
      "Epoch 972/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 331729.0625 - mae: 333.5276 - val_loss: 374610.2188 - val_mae: 364.4105\n",
      "Epoch 973/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 296103.7812 - mae: 327.1214 - val_loss: 370111.3125 - val_mae: 360.1822\n",
      "Epoch 974/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 317262.0938 - mae: 327.9810 - val_loss: 373313.6875 - val_mae: 362.7534\n",
      "Epoch 975/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 278107.8438 - mae: 321.3407 - val_loss: 370200.1875 - val_mae: 359.7318\n",
      "Epoch 976/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 366545.0625 - mae: 337.5624 - val_loss: 372759.6875 - val_mae: 362.7484\n",
      "Epoch 977/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 290226.3438 - mae: 318.6768 - val_loss: 372060.6250 - val_mae: 360.6549\n",
      "Epoch 978/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 300464.0625 - mae: 325.5563 - val_loss: 372661.6875 - val_mae: 361.4870\n",
      "Epoch 979/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 333413.3125 - mae: 337.9985 - val_loss: 372081.2812 - val_mae: 360.7499\n",
      "Epoch 980/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 316556.9375 - mae: 332.0888 - val_loss: 371027.6875 - val_mae: 361.0605\n",
      "Epoch 981/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 277536.0938 - mae: 310.6675 - val_loss: 369226.7812 - val_mae: 359.2264\n",
      "Epoch 982/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 298175.1250 - mae: 311.6082 - val_loss: 374241.0312 - val_mae: 363.0916\n",
      "Epoch 983/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 366169.0000 - mae: 353.5641 - val_loss: 371377.8750 - val_mae: 360.9874\n",
      "Epoch 984/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 292700.3750 - mae: 319.2949 - val_loss: 374161.6250 - val_mae: 363.4181\n",
      "Epoch 985/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 320544.1875 - mae: 335.6324 - val_loss: 372047.8125 - val_mae: 360.6830\n",
      "Epoch 986/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 310527.4375 - mae: 323.7690 - val_loss: 371943.8125 - val_mae: 361.4497\n",
      "Epoch 987/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 270854.6875 - mae: 307.6801 - val_loss: 373778.4375 - val_mae: 362.5838\n",
      "Epoch 988/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 277052.9688 - mae: 311.6497 - val_loss: 372504.8125 - val_mae: 362.7120\n",
      "Epoch 989/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 351490.3750 - mae: 340.6805 - val_loss: 369136.4375 - val_mae: 357.7084\n",
      "Epoch 990/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 291345.3438 - mae: 313.9416 - val_loss: 372377.8125 - val_mae: 362.0053\n",
      "Epoch 991/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 316493.8125 - mae: 326.1878 - val_loss: 373295.4062 - val_mae: 362.2758\n",
      "Epoch 992/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 289429.6562 - mae: 321.8430 - val_loss: 372017.3750 - val_mae: 361.5354\n",
      "Epoch 993/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 270908.0938 - mae: 306.3707 - val_loss: 370105.5625 - val_mae: 359.9005\n",
      "Epoch 994/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 278353.2188 - mae: 317.8277 - val_loss: 371129.5312 - val_mae: 359.7919\n",
      "Epoch 995/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 274073.1875 - mae: 308.2101 - val_loss: 374322.4375 - val_mae: 363.0833\n",
      "Epoch 996/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 276341.5000 - mae: 315.0375 - val_loss: 369518.5938 - val_mae: 359.3336\n",
      "Epoch 997/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 295181.9688 - mae: 318.1076 - val_loss: 375299.5938 - val_mae: 363.6661\n",
      "Epoch 998/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 314122.2812 - mae: 330.1153 - val_loss: 370870.4688 - val_mae: 360.6772\n",
      "Epoch 999/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 302416.7812 - mae: 318.9978 - val_loss: 374272.3438 - val_mae: 363.4746\n",
      "Epoch 1000/1000\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 363393.6250 - mae: 346.9678 - val_loss: 370491.7188 - val_mae: 359.6969\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1),  # Output layer for regression\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation mean absolute error values\n",
    "plt.plot(history.history[\"mae\"], label=\"Train MAE\")\n",
    "plt.plot(history.history[\"val_mae\"], label=\"Validation MAE\")\n",
    "plt.title(\"Model MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 359.6969369636553\n",
      "mse: 370491.67038723046\n",
      "mape: 0.2656286586475834\n",
      "r2: 0.7656298279762268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"mae:\", mae)\n",
    "print(\"mse:\", mse)\n",
    "print(\"mape:\", mape)\n",
    "print(\"r2:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
